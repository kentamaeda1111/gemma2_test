{
  "best_metric": 174567040.0,
  "best_model_checkpoint": "models/kaggle_model_ver2/model/checkpoint-3100",
  "epoch": 24.0604343720491,
  "eval_steps": 100,
  "global_step": 3200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07554296506137866,
      "grad_norm": 22.839014053344727,
      "learning_rate": 5.050505050505051e-06,
      "loss": 5.2168,
      "step": 10
    },
    {
      "epoch": 0.1510859301227573,
      "grad_norm": 26.57324981689453,
      "learning_rate": 1.0101010101010101e-05,
      "loss": 5.1863,
      "step": 20
    },
    {
      "epoch": 0.22662889518413598,
      "grad_norm": 18.661489486694336,
      "learning_rate": 1.5151515151515153e-05,
      "loss": 5.0483,
      "step": 30
    },
    {
      "epoch": 0.3021718602455146,
      "grad_norm": 20.66554069519043,
      "learning_rate": 2.0202020202020203e-05,
      "loss": 4.8684,
      "step": 40
    },
    {
      "epoch": 0.3777148253068933,
      "grad_norm": 7.778426170349121,
      "learning_rate": 2.5252525252525256e-05,
      "loss": 4.4297,
      "step": 50
    },
    {
      "epoch": 0.45325779036827196,
      "grad_norm": 7.029818058013916,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 3.8902,
      "step": 60
    },
    {
      "epoch": 0.5288007554296507,
      "grad_norm": 1.735948920249939,
      "learning_rate": 3.535353535353535e-05,
      "loss": 3.2613,
      "step": 70
    },
    {
      "epoch": 0.6043437204910292,
      "grad_norm": 1.5620161294937134,
      "learning_rate": 4.0404040404040405e-05,
      "loss": 2.9321,
      "step": 80
    },
    {
      "epoch": 0.6798866855524079,
      "grad_norm": 1.3789511919021606,
      "learning_rate": 4.545454545454546e-05,
      "loss": 2.6747,
      "step": 90
    },
    {
      "epoch": 0.7554296506137866,
      "grad_norm": 1.2176296710968018,
      "learning_rate": 5.050505050505051e-05,
      "loss": 2.4518,
      "step": 100
    },
    {
      "epoch": 0.7554296506137866,
      "eval_loss": 11.902316093444824,
      "eval_perplexity": 147608.109375,
      "eval_runtime": 21.1045,
      "eval_samples_per_second": 2.369,
      "eval_steps_per_second": 1.185,
      "step": 100
    },
    {
      "epoch": 0.8309726156751652,
      "grad_norm": 1.1876776218414307,
      "learning_rate": 5.555555555555556e-05,
      "loss": 2.3248,
      "step": 110
    },
    {
      "epoch": 0.9065155807365439,
      "grad_norm": 1.2616337537765503,
      "learning_rate": 6.060606060606061e-05,
      "loss": 2.2513,
      "step": 120
    },
    {
      "epoch": 0.9820585457979226,
      "grad_norm": 1.2802422046661377,
      "learning_rate": 6.565656565656566e-05,
      "loss": 2.1841,
      "step": 130
    },
    {
      "epoch": 1.052880075542965,
      "grad_norm": 1.3468912839889526,
      "learning_rate": 7.07070707070707e-05,
      "loss": 2.1209,
      "step": 140
    },
    {
      "epoch": 1.1284230406043436,
      "grad_norm": 1.3129953145980835,
      "learning_rate": 7.575757575757576e-05,
      "loss": 2.0891,
      "step": 150
    },
    {
      "epoch": 1.2039660056657224,
      "grad_norm": 1.23537278175354,
      "learning_rate": 8.080808080808081e-05,
      "loss": 2.0718,
      "step": 160
    },
    {
      "epoch": 1.279508970727101,
      "grad_norm": 1.4666646718978882,
      "learning_rate": 8.585858585858586e-05,
      "loss": 2.0648,
      "step": 170
    },
    {
      "epoch": 1.3550519357884796,
      "grad_norm": 1.4125761985778809,
      "learning_rate": 9.090909090909092e-05,
      "loss": 2.0261,
      "step": 180
    },
    {
      "epoch": 1.4305949008498584,
      "grad_norm": 1.378096342086792,
      "learning_rate": 9.595959595959596e-05,
      "loss": 2.0136,
      "step": 190
    },
    {
      "epoch": 1.506137865911237,
      "grad_norm": 1.499813199043274,
      "learning_rate": 0.00010101010101010102,
      "loss": 1.9984,
      "step": 200
    },
    {
      "epoch": 1.506137865911237,
      "eval_loss": 12.686365127563477,
      "eval_perplexity": 323309.4375,
      "eval_runtime": 21.5,
      "eval_samples_per_second": 2.326,
      "eval_steps_per_second": 1.163,
      "step": 200
    },
    {
      "epoch": 1.5816808309726156,
      "grad_norm": 1.38109290599823,
      "learning_rate": 0.00010606060606060606,
      "loss": 1.9856,
      "step": 210
    },
    {
      "epoch": 1.6572237960339944,
      "grad_norm": 1.4455305337905884,
      "learning_rate": 0.00011111111111111112,
      "loss": 1.9598,
      "step": 220
    },
    {
      "epoch": 1.732766761095373,
      "grad_norm": 1.5766876935958862,
      "learning_rate": 0.00011616161616161616,
      "loss": 1.9004,
      "step": 230
    },
    {
      "epoch": 1.8083097261567516,
      "grad_norm": 1.5038244724273682,
      "learning_rate": 0.00012121212121212122,
      "loss": 1.9107,
      "step": 240
    },
    {
      "epoch": 1.8838526912181304,
      "grad_norm": 1.417208194732666,
      "learning_rate": 0.00012626262626262626,
      "loss": 1.9101,
      "step": 250
    },
    {
      "epoch": 1.959395656279509,
      "grad_norm": 1.6603326797485352,
      "learning_rate": 0.00013131313131313133,
      "loss": 1.9035,
      "step": 260
    },
    {
      "epoch": 2.0302171860245513,
      "grad_norm": 1.484291434288025,
      "learning_rate": 0.00013636363636363637,
      "loss": 1.8639,
      "step": 270
    },
    {
      "epoch": 2.10576015108593,
      "grad_norm": 1.642360806465149,
      "learning_rate": 0.0001414141414141414,
      "loss": 1.8449,
      "step": 280
    },
    {
      "epoch": 2.181303116147309,
      "grad_norm": 1.4533944129943848,
      "learning_rate": 0.00014646464646464648,
      "loss": 1.824,
      "step": 290
    },
    {
      "epoch": 2.2568460812086872,
      "grad_norm": 1.6784119606018066,
      "learning_rate": 0.00015151515151515152,
      "loss": 1.8179,
      "step": 300
    },
    {
      "epoch": 2.2568460812086872,
      "eval_loss": 13.170650482177734,
      "eval_perplexity": 524735.9375,
      "eval_runtime": 21.196,
      "eval_samples_per_second": 2.359,
      "eval_steps_per_second": 1.179,
      "step": 300
    },
    {
      "epoch": 2.332389046270066,
      "grad_norm": 1.6347956657409668,
      "learning_rate": 0.00015656565656565658,
      "loss": 1.7976,
      "step": 310
    },
    {
      "epoch": 2.407932011331445,
      "grad_norm": 1.6964715719223022,
      "learning_rate": 0.00016161616161616162,
      "loss": 1.7821,
      "step": 320
    },
    {
      "epoch": 2.4834749763928237,
      "grad_norm": 1.5327692031860352,
      "learning_rate": 0.0001666666666666667,
      "loss": 1.8227,
      "step": 330
    },
    {
      "epoch": 2.559017941454202,
      "grad_norm": 1.5612268447875977,
      "learning_rate": 0.00017171717171717173,
      "loss": 1.8033,
      "step": 340
    },
    {
      "epoch": 2.634560906515581,
      "grad_norm": 1.5614333152770996,
      "learning_rate": 0.0001767676767676768,
      "loss": 1.7636,
      "step": 350
    },
    {
      "epoch": 2.710103871576959,
      "grad_norm": 1.5273089408874512,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.7654,
      "step": 360
    },
    {
      "epoch": 2.785646836638338,
      "grad_norm": 1.564075231552124,
      "learning_rate": 0.00018686868686868687,
      "loss": 1.7498,
      "step": 370
    },
    {
      "epoch": 2.861189801699717,
      "grad_norm": 1.606429934501648,
      "learning_rate": 0.00019191919191919191,
      "loss": 1.7611,
      "step": 380
    },
    {
      "epoch": 2.9367327667610956,
      "grad_norm": 1.498009443283081,
      "learning_rate": 0.00019696969696969698,
      "loss": 1.7843,
      "step": 390
    },
    {
      "epoch": 3.0075542965061377,
      "grad_norm": 1.5225976705551147,
      "learning_rate": 0.0001999993783958694,
      "loss": 1.787,
      "step": 400
    },
    {
      "epoch": 3.0075542965061377,
      "eval_loss": 13.5222806930542,
      "eval_perplexity": 745850.6875,
      "eval_runtime": 21.1584,
      "eval_samples_per_second": 2.363,
      "eval_steps_per_second": 1.182,
      "step": 400
    },
    {
      "epoch": 3.0830972615675165,
      "grad_norm": 1.5286225080490112,
      "learning_rate": 0.0001999923854381492,
      "loss": 1.6952,
      "step": 410
    },
    {
      "epoch": 3.1586402266288953,
      "grad_norm": 1.5830167531967163,
      "learning_rate": 0.0001999776230627102,
      "loss": 1.6967,
      "step": 420
    },
    {
      "epoch": 3.2341831916902737,
      "grad_norm": 1.6240873336791992,
      "learning_rate": 0.00019995509241659036,
      "loss": 1.6814,
      "step": 430
    },
    {
      "epoch": 3.3097261567516525,
      "grad_norm": 1.4719346761703491,
      "learning_rate": 0.00019992479525042303,
      "loss": 1.692,
      "step": 440
    },
    {
      "epoch": 3.3852691218130313,
      "grad_norm": 1.7587562799453735,
      "learning_rate": 0.0001998867339183008,
      "loss": 1.6962,
      "step": 450
    },
    {
      "epoch": 3.4608120868744097,
      "grad_norm": 1.5243481397628784,
      "learning_rate": 0.0001998409113775928,
      "loss": 1.6825,
      "step": 460
    },
    {
      "epoch": 3.5363550519357885,
      "grad_norm": 1.520776391029358,
      "learning_rate": 0.0001997873311887147,
      "loss": 1.6896,
      "step": 470
    },
    {
      "epoch": 3.6118980169971673,
      "grad_norm": 1.5968056917190552,
      "learning_rate": 0.00019972599751485226,
      "loss": 1.6489,
      "step": 480
    },
    {
      "epoch": 3.6874409820585456,
      "grad_norm": 1.5496097803115845,
      "learning_rate": 0.0001996569151216376,
      "loss": 1.6712,
      "step": 490
    },
    {
      "epoch": 3.7629839471199245,
      "grad_norm": 1.4799628257751465,
      "learning_rate": 0.00019958008937677918,
      "loss": 1.7027,
      "step": 500
    },
    {
      "epoch": 3.7629839471199245,
      "eval_loss": 13.852898597717285,
      "eval_perplexity": 1038095.75,
      "eval_runtime": 21.3247,
      "eval_samples_per_second": 2.345,
      "eval_steps_per_second": 1.172,
      "step": 500
    },
    {
      "epoch": 3.8385269121813033,
      "grad_norm": 1.5148998498916626,
      "learning_rate": 0.0001994955262496446,
      "loss": 1.6843,
      "step": 510
    },
    {
      "epoch": 3.9140698772426816,
      "grad_norm": 1.496881127357483,
      "learning_rate": 0.00019940323231079673,
      "loss": 1.6661,
      "step": 520
    },
    {
      "epoch": 3.9896128423040604,
      "grad_norm": 1.4307565689086914,
      "learning_rate": 0.00019930321473148329,
      "loss": 1.6785,
      "step": 530
    },
    {
      "epoch": 4.0604343720491025,
      "grad_norm": 1.5402730703353882,
      "learning_rate": 0.00019919548128307954,
      "loss": 1.6088,
      "step": 540
    },
    {
      "epoch": 4.135977337110481,
      "grad_norm": 1.6345430612564087,
      "learning_rate": 0.00019908004033648453,
      "loss": 1.5778,
      "step": 550
    },
    {
      "epoch": 4.21152030217186,
      "grad_norm": 1.4982078075408936,
      "learning_rate": 0.00019895690086147065,
      "loss": 1.5712,
      "step": 560
    },
    {
      "epoch": 4.287063267233239,
      "grad_norm": 1.6446633338928223,
      "learning_rate": 0.00019882607242598663,
      "loss": 1.5781,
      "step": 570
    },
    {
      "epoch": 4.362606232294618,
      "grad_norm": 1.6156443357467651,
      "learning_rate": 0.00019868756519541414,
      "loss": 1.5814,
      "step": 580
    },
    {
      "epoch": 4.4381491973559966,
      "grad_norm": 1.5146814584732056,
      "learning_rate": 0.00019854138993177802,
      "loss": 1.5616,
      "step": 590
    },
    {
      "epoch": 4.5136921624173745,
      "grad_norm": 1.5744229555130005,
      "learning_rate": 0.00019838755799290994,
      "loss": 1.5551,
      "step": 600
    },
    {
      "epoch": 4.5136921624173745,
      "eval_loss": 14.314391136169434,
      "eval_perplexity": 1646876.625,
      "eval_runtime": 21.1027,
      "eval_samples_per_second": 2.369,
      "eval_steps_per_second": 1.185,
      "step": 600
    },
    {
      "epoch": 4.589235127478753,
      "grad_norm": 1.5194836854934692,
      "learning_rate": 0.00019822608133156596,
      "loss": 1.5903,
      "step": 610
    },
    {
      "epoch": 4.664778092540132,
      "grad_norm": 1.6229186058044434,
      "learning_rate": 0.00019805697249449775,
      "loss": 1.5586,
      "step": 620
    },
    {
      "epoch": 4.740321057601511,
      "grad_norm": 1.6121000051498413,
      "learning_rate": 0.00019788024462147788,
      "loss": 1.5602,
      "step": 630
    },
    {
      "epoch": 4.81586402266289,
      "grad_norm": 1.6996076107025146,
      "learning_rate": 0.0001976959114442786,
      "loss": 1.5771,
      "step": 640
    },
    {
      "epoch": 4.8914069877242685,
      "grad_norm": 1.4761484861373901,
      "learning_rate": 0.00019750398728560507,
      "loss": 1.5323,
      "step": 650
    },
    {
      "epoch": 4.966949952785647,
      "grad_norm": 1.5199843645095825,
      "learning_rate": 0.00019730448705798239,
      "loss": 1.582,
      "step": 660
    },
    {
      "epoch": 5.037771482530689,
      "grad_norm": 1.49739408493042,
      "learning_rate": 0.00019709742626259694,
      "loss": 1.4874,
      "step": 670
    },
    {
      "epoch": 5.113314447592068,
      "grad_norm": 1.680090069770813,
      "learning_rate": 0.00019688282098809194,
      "loss": 1.4395,
      "step": 680
    },
    {
      "epoch": 5.188857412653447,
      "grad_norm": 1.7832558155059814,
      "learning_rate": 0.00019666068790931732,
      "loss": 1.4243,
      "step": 690
    },
    {
      "epoch": 5.264400377714825,
      "grad_norm": 1.6842732429504395,
      "learning_rate": 0.00019643104428603413,
      "loss": 1.4645,
      "step": 700
    },
    {
      "epoch": 5.264400377714825,
      "eval_loss": 14.859990119934082,
      "eval_perplexity": 2841919.0,
      "eval_runtime": 21.5423,
      "eval_samples_per_second": 2.321,
      "eval_steps_per_second": 1.161,
      "step": 700
    },
    {
      "epoch": 5.339943342776204,
      "grad_norm": 1.6892085075378418,
      "learning_rate": 0.00019619390796157338,
      "loss": 1.4559,
      "step": 710
    },
    {
      "epoch": 5.415486307837583,
      "grad_norm": 1.6196630001068115,
      "learning_rate": 0.00019594929736144976,
      "loss": 1.4711,
      "step": 720
    },
    {
      "epoch": 5.491029272898961,
      "grad_norm": 1.7693270444869995,
      "learning_rate": 0.00019569723149192979,
      "loss": 1.4551,
      "step": 730
    },
    {
      "epoch": 5.56657223796034,
      "grad_norm": 1.8002914190292358,
      "learning_rate": 0.00019543772993855512,
      "loss": 1.4793,
      "step": 740
    },
    {
      "epoch": 5.642115203021719,
      "grad_norm": 1.7861567735671997,
      "learning_rate": 0.0001951708128646208,
      "loss": 1.4967,
      "step": 750
    },
    {
      "epoch": 5.717658168083097,
      "grad_norm": 1.7342015504837036,
      "learning_rate": 0.00019489650100960851,
      "loss": 1.4672,
      "step": 760
    },
    {
      "epoch": 5.793201133144476,
      "grad_norm": 1.7380821704864502,
      "learning_rate": 0.00019461481568757506,
      "loss": 1.4537,
      "step": 770
    },
    {
      "epoch": 5.8687440982058545,
      "grad_norm": 1.610924243927002,
      "learning_rate": 0.00019432577878549637,
      "loss": 1.4383,
      "step": 780
    },
    {
      "epoch": 5.944287063267233,
      "grad_norm": 1.6132241487503052,
      "learning_rate": 0.0001940294127615668,
      "loss": 1.4574,
      "step": 790
    },
    {
      "epoch": 6.015108593012275,
      "grad_norm": 1.7069612741470337,
      "learning_rate": 0.00019372574064345423,
      "loss": 1.4463,
      "step": 800
    },
    {
      "epoch": 6.015108593012275,
      "eval_loss": 14.95211410522461,
      "eval_perplexity": 3116166.5,
      "eval_runtime": 21.1108,
      "eval_samples_per_second": 2.368,
      "eval_steps_per_second": 1.184,
      "step": 800
    },
    {
      "epoch": 6.090651558073654,
      "grad_norm": 1.8366446495056152,
      "learning_rate": 0.00019341478602651069,
      "loss": 1.3361,
      "step": 810
    },
    {
      "epoch": 6.166194523135033,
      "grad_norm": 1.8371222019195557,
      "learning_rate": 0.000193096573071939,
      "loss": 1.3049,
      "step": 820
    },
    {
      "epoch": 6.241737488196412,
      "grad_norm": 1.8021886348724365,
      "learning_rate": 0.0001927711265049156,
      "loss": 1.3134,
      "step": 830
    },
    {
      "epoch": 6.317280453257791,
      "grad_norm": 1.8930625915527344,
      "learning_rate": 0.0001924384716126692,
      "loss": 1.35,
      "step": 840
    },
    {
      "epoch": 6.3928234183191694,
      "grad_norm": 1.7265011072158813,
      "learning_rate": 0.00019209863424251618,
      "loss": 1.3373,
      "step": 850
    },
    {
      "epoch": 6.468366383380547,
      "grad_norm": 1.7620611190795898,
      "learning_rate": 0.00019175164079985194,
      "loss": 1.3335,
      "step": 860
    },
    {
      "epoch": 6.543909348441926,
      "grad_norm": 1.8286312818527222,
      "learning_rate": 0.0001913975182460996,
      "loss": 1.3434,
      "step": 870
    },
    {
      "epoch": 6.619452313503305,
      "grad_norm": 1.805310606956482,
      "learning_rate": 0.0001910362940966147,
      "loss": 1.3533,
      "step": 880
    },
    {
      "epoch": 6.694995278564684,
      "grad_norm": 1.7143528461456299,
      "learning_rate": 0.0001906679964185475,
      "loss": 1.3998,
      "step": 890
    },
    {
      "epoch": 6.770538243626063,
      "grad_norm": 1.954660177230835,
      "learning_rate": 0.00019029265382866214,
      "loss": 1.3489,
      "step": 900
    },
    {
      "epoch": 6.770538243626063,
      "eval_loss": 15.27166748046875,
      "eval_perplexity": 4289443.0,
      "eval_runtime": 21.3207,
      "eval_samples_per_second": 2.345,
      "eval_steps_per_second": 1.173,
      "step": 900
    },
    {
      "epoch": 6.8460812086874405,
      "grad_norm": 1.8549679517745972,
      "learning_rate": 0.000189910295491113,
      "loss": 1.3656,
      "step": 910
    },
    {
      "epoch": 6.921624173748819,
      "grad_norm": 1.8219515085220337,
      "learning_rate": 0.00018952095111517876,
      "loss": 1.3615,
      "step": 920
    },
    {
      "epoch": 6.997167138810198,
      "grad_norm": 1.911974310874939,
      "learning_rate": 0.00018912465095295388,
      "loss": 1.3687,
      "step": 930
    },
    {
      "epoch": 7.067988668555241,
      "grad_norm": 1.9368888139724731,
      "learning_rate": 0.00018872142579699818,
      "loss": 1.2473,
      "step": 940
    },
    {
      "epoch": 7.143531633616619,
      "grad_norm": 1.9899628162384033,
      "learning_rate": 0.00018831130697794397,
      "loss": 1.2002,
      "step": 950
    },
    {
      "epoch": 7.219074598677998,
      "grad_norm": 2.297025442123413,
      "learning_rate": 0.00018789432636206197,
      "loss": 1.2293,
      "step": 960
    },
    {
      "epoch": 7.294617563739377,
      "grad_norm": 2.0685250759124756,
      "learning_rate": 0.0001874705163487851,
      "loss": 1.2191,
      "step": 970
    },
    {
      "epoch": 7.3701605288007555,
      "grad_norm": 2.085296630859375,
      "learning_rate": 0.0001870399098681911,
      "loss": 1.2321,
      "step": 980
    },
    {
      "epoch": 7.445703493862134,
      "grad_norm": 2.1481738090515137,
      "learning_rate": 0.00018660254037844388,
      "loss": 1.231,
      "step": 990
    },
    {
      "epoch": 7.521246458923513,
      "grad_norm": 1.9413776397705078,
      "learning_rate": 0.00018615844186319378,
      "loss": 1.2199,
      "step": 1000
    },
    {
      "epoch": 7.521246458923513,
      "eval_loss": 15.444697380065918,
      "eval_perplexity": 5099726.0,
      "eval_runtime": 21.581,
      "eval_samples_per_second": 2.317,
      "eval_steps_per_second": 1.158,
      "step": 1000
    },
    {
      "epoch": 7.596789423984891,
      "grad_norm": 2.1405558586120605,
      "learning_rate": 0.00018570764882893702,
      "loss": 1.2176,
      "step": 1010
    },
    {
      "epoch": 7.67233238904627,
      "grad_norm": 1.9581001996994019,
      "learning_rate": 0.00018525019630233463,
      "loss": 1.2618,
      "step": 1020
    },
    {
      "epoch": 7.747875354107649,
      "grad_norm": 2.1118295192718506,
      "learning_rate": 0.0001847861198274908,
      "loss": 1.2431,
      "step": 1030
    },
    {
      "epoch": 7.823418319169027,
      "grad_norm": 1.987623691558838,
      "learning_rate": 0.00018431545546319112,
      "loss": 1.2559,
      "step": 1040
    },
    {
      "epoch": 7.898961284230406,
      "grad_norm": 1.971848726272583,
      "learning_rate": 0.00018383823978010075,
      "loss": 1.254,
      "step": 1050
    },
    {
      "epoch": 7.974504249291785,
      "grad_norm": 2.0665197372436523,
      "learning_rate": 0.00018335450985792307,
      "loss": 1.2529,
      "step": 1060
    },
    {
      "epoch": 8.045325779036828,
      "grad_norm": 1.9887672662734985,
      "learning_rate": 0.0001828643032825183,
      "loss": 1.1391,
      "step": 1070
    },
    {
      "epoch": 8.120868744098205,
      "grad_norm": 2.1100587844848633,
      "learning_rate": 0.0001823676581429833,
      "loss": 1.1026,
      "step": 1080
    },
    {
      "epoch": 8.196411709159584,
      "grad_norm": 2.241306781768799,
      "learning_rate": 0.00018186461302869194,
      "loss": 1.0699,
      "step": 1090
    },
    {
      "epoch": 8.271954674220963,
      "grad_norm": 2.2354044914245605,
      "learning_rate": 0.00018135520702629675,
      "loss": 1.1215,
      "step": 1100
    },
    {
      "epoch": 8.271954674220963,
      "eval_loss": 16.136491775512695,
      "eval_perplexity": 10185664.0,
      "eval_runtime": 21.1062,
      "eval_samples_per_second": 2.369,
      "eval_steps_per_second": 1.184,
      "step": 1100
    },
    {
      "epoch": 8.347497639282341,
      "grad_norm": 2.3151626586914062,
      "learning_rate": 0.0001808394797166919,
      "loss": 1.1307,
      "step": 1110
    },
    {
      "epoch": 8.42304060434372,
      "grad_norm": 2.3041749000549316,
      "learning_rate": 0.0001803174711719376,
      "loss": 1.0856,
      "step": 1120
    },
    {
      "epoch": 8.498583569405099,
      "grad_norm": 2.148787021636963,
      "learning_rate": 0.00017978922195214673,
      "loss": 1.1235,
      "step": 1130
    },
    {
      "epoch": 8.574126534466478,
      "grad_norm": 2.2093446254730225,
      "learning_rate": 0.00017925477310233316,
      "loss": 1.1355,
      "step": 1140
    },
    {
      "epoch": 8.649669499527857,
      "grad_norm": 2.1963675022125244,
      "learning_rate": 0.00017871416614922265,
      "loss": 1.143,
      "step": 1150
    },
    {
      "epoch": 8.725212464589235,
      "grad_norm": 2.2636735439300537,
      "learning_rate": 0.00017816744309802603,
      "loss": 1.159,
      "step": 1160
    },
    {
      "epoch": 8.800755429650614,
      "grad_norm": 2.1328916549682617,
      "learning_rate": 0.0001776146464291757,
      "loss": 1.1339,
      "step": 1170
    },
    {
      "epoch": 8.876298394711993,
      "grad_norm": 2.3122379779815674,
      "learning_rate": 0.00017705581909502457,
      "loss": 1.1571,
      "step": 1180
    },
    {
      "epoch": 8.951841359773372,
      "grad_norm": 2.3282597064971924,
      "learning_rate": 0.00017649100451650889,
      "loss": 1.146,
      "step": 1190
    },
    {
      "epoch": 9.022662889518413,
      "grad_norm": 2.085566759109497,
      "learning_rate": 0.00017592024657977432,
      "loss": 1.0995,
      "step": 1200
    },
    {
      "epoch": 9.022662889518413,
      "eval_loss": 16.272565841674805,
      "eval_perplexity": 11670395.0,
      "eval_runtime": 22.0636,
      "eval_samples_per_second": 2.266,
      "eval_steps_per_second": 1.133,
      "step": 1200
    },
    {
      "epoch": 9.098205854579792,
      "grad_norm": 2.331599473953247,
      "learning_rate": 0.00017534358963276607,
      "loss": 1.0001,
      "step": 1210
    },
    {
      "epoch": 9.17374881964117,
      "grad_norm": 2.3388736248016357,
      "learning_rate": 0.00017476107848178295,
      "loss": 0.9685,
      "step": 1220
    },
    {
      "epoch": 9.24929178470255,
      "grad_norm": 2.4255239963531494,
      "learning_rate": 0.00017417275838799596,
      "loss": 0.9789,
      "step": 1230
    },
    {
      "epoch": 9.324834749763928,
      "grad_norm": 2.482008218765259,
      "learning_rate": 0.00017357867506393154,
      "loss": 0.9947,
      "step": 1240
    },
    {
      "epoch": 9.400377714825307,
      "grad_norm": 2.45341420173645,
      "learning_rate": 0.00017297887466991962,
      "loss": 1.0052,
      "step": 1250
    },
    {
      "epoch": 9.475920679886686,
      "grad_norm": 2.3377504348754883,
      "learning_rate": 0.00017237340381050703,
      "loss": 1.0036,
      "step": 1260
    },
    {
      "epoch": 9.551463644948065,
      "grad_norm": 2.5064260959625244,
      "learning_rate": 0.00017176230953083626,
      "loss": 1.0087,
      "step": 1270
    },
    {
      "epoch": 9.627006610009444,
      "grad_norm": 2.515594959259033,
      "learning_rate": 0.00017114563931299018,
      "loss": 1.0582,
      "step": 1280
    },
    {
      "epoch": 9.702549575070822,
      "grad_norm": 2.623656988143921,
      "learning_rate": 0.00017052344107230241,
      "loss": 1.0226,
      "step": 1290
    },
    {
      "epoch": 9.7780925401322,
      "grad_norm": 2.378232479095459,
      "learning_rate": 0.00016989576315363465,
      "loss": 1.0398,
      "step": 1300
    },
    {
      "epoch": 9.7780925401322,
      "eval_loss": 16.522912979125977,
      "eval_perplexity": 14990286.0,
      "eval_runtime": 20.947,
      "eval_samples_per_second": 2.387,
      "eval_steps_per_second": 1.193,
      "step": 1300
    },
    {
      "epoch": 9.853635505193578,
      "grad_norm": 2.4620182514190674,
      "learning_rate": 0.0001692626543276199,
      "loss": 1.0422,
      "step": 1310
    },
    {
      "epoch": 9.929178470254957,
      "grad_norm": 2.385449171066284,
      "learning_rate": 0.0001686241637868734,
      "loss": 1.0428,
      "step": 1320
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.138897895812988,
      "learning_rate": 0.00016798034114216983,
      "loss": 1.0378,
      "step": 1330
    },
    {
      "epoch": 10.075542965061379,
      "grad_norm": 2.6258251667022705,
      "learning_rate": 0.00016733123641858913,
      "loss": 0.8743,
      "step": 1340
    },
    {
      "epoch": 10.151085930122758,
      "grad_norm": 2.6176204681396484,
      "learning_rate": 0.00016667690005162916,
      "loss": 0.8799,
      "step": 1350
    },
    {
      "epoch": 10.226628895184136,
      "grad_norm": 2.611130952835083,
      "learning_rate": 0.00016601738288328692,
      "loss": 0.8922,
      "step": 1360
    },
    {
      "epoch": 10.302171860245515,
      "grad_norm": 2.772217035293579,
      "learning_rate": 0.00016535273615810817,
      "loss": 0.8872,
      "step": 1370
    },
    {
      "epoch": 10.377714825306894,
      "grad_norm": 2.6529548168182373,
      "learning_rate": 0.00016468301151920575,
      "loss": 0.9026,
      "step": 1380
    },
    {
      "epoch": 10.453257790368273,
      "grad_norm": 2.657611131668091,
      "learning_rate": 0.00016400826100424688,
      "loss": 0.9014,
      "step": 1390
    },
    {
      "epoch": 10.52880075542965,
      "grad_norm": 2.8394062519073486,
      "learning_rate": 0.0001633285370414098,
      "loss": 0.9257,
      "step": 1400
    },
    {
      "epoch": 10.52880075542965,
      "eval_loss": 16.89583396911621,
      "eval_perplexity": 21765440.0,
      "eval_runtime": 21.3387,
      "eval_samples_per_second": 2.343,
      "eval_steps_per_second": 1.172,
      "step": 1400
    },
    {
      "epoch": 10.604343720491029,
      "grad_norm": 2.6391234397888184,
      "learning_rate": 0.00016264389244531014,
      "loss": 0.9094,
      "step": 1410
    },
    {
      "epoch": 10.679886685552407,
      "grad_norm": 2.7251596450805664,
      "learning_rate": 0.0001619543804128971,
      "loss": 0.9426,
      "step": 1420
    },
    {
      "epoch": 10.755429650613786,
      "grad_norm": 2.6826484203338623,
      "learning_rate": 0.0001612600545193203,
      "loss": 0.926,
      "step": 1430
    },
    {
      "epoch": 10.830972615675165,
      "grad_norm": 2.6760330200195312,
      "learning_rate": 0.00016056096871376667,
      "loss": 0.9322,
      "step": 1440
    },
    {
      "epoch": 10.906515580736544,
      "grad_norm": 2.6685519218444824,
      "learning_rate": 0.00015985717731526887,
      "loss": 0.9309,
      "step": 1450
    },
    {
      "epoch": 10.982058545797923,
      "grad_norm": 2.5817606449127197,
      "learning_rate": 0.00015914873500848446,
      "loss": 0.9332,
      "step": 1460
    },
    {
      "epoch": 11.052880075542966,
      "grad_norm": 2.5588538646698,
      "learning_rate": 0.0001584356968394471,
      "loss": 0.8211,
      "step": 1470
    },
    {
      "epoch": 11.128423040604345,
      "grad_norm": 2.774805784225464,
      "learning_rate": 0.00015771811821128933,
      "loss": 0.7731,
      "step": 1480
    },
    {
      "epoch": 11.203966005665722,
      "grad_norm": 2.8281497955322266,
      "learning_rate": 0.0001569960548799378,
      "loss": 0.7731,
      "step": 1490
    },
    {
      "epoch": 11.2795089707271,
      "grad_norm": 2.792792320251465,
      "learning_rate": 0.00015626956294978103,
      "loss": 0.7899,
      "step": 1500
    },
    {
      "epoch": 11.2795089707271,
      "eval_loss": 17.377288818359375,
      "eval_perplexity": 35225784.0,
      "eval_runtime": 21.1556,
      "eval_samples_per_second": 2.363,
      "eval_steps_per_second": 1.182,
      "step": 1500
    },
    {
      "epoch": 11.35505193578848,
      "grad_norm": 2.8058042526245117,
      "learning_rate": 0.00015553869886931007,
      "loss": 0.8079,
      "step": 1510
    },
    {
      "epoch": 11.430594900849858,
      "grad_norm": 2.870722770690918,
      "learning_rate": 0.00015480351942673246,
      "loss": 0.8064,
      "step": 1520
    },
    {
      "epoch": 11.506137865911237,
      "grad_norm": 2.8978469371795654,
      "learning_rate": 0.00015406408174555976,
      "loss": 0.8335,
      "step": 1530
    },
    {
      "epoch": 11.581680830972616,
      "grad_norm": 3.0476717948913574,
      "learning_rate": 0.00015332044328016914,
      "loss": 0.8168,
      "step": 1540
    },
    {
      "epoch": 11.657223796033994,
      "grad_norm": 2.70918607711792,
      "learning_rate": 0.00015257266181133898,
      "loss": 0.8165,
      "step": 1550
    },
    {
      "epoch": 11.732766761095373,
      "grad_norm": 2.916414499282837,
      "learning_rate": 0.00015182079544175955,
      "loss": 0.8444,
      "step": 1560
    },
    {
      "epoch": 11.808309726156752,
      "grad_norm": 2.944601058959961,
      "learning_rate": 0.0001510649025915182,
      "loss": 0.84,
      "step": 1570
    },
    {
      "epoch": 11.88385269121813,
      "grad_norm": 2.8674323558807373,
      "learning_rate": 0.0001503050419935602,
      "loss": 0.8488,
      "step": 1580
    },
    {
      "epoch": 11.95939565627951,
      "grad_norm": 2.980053424835205,
      "learning_rate": 0.00014954127268912526,
      "loss": 0.8416,
      "step": 1590
    },
    {
      "epoch": 12.03021718602455,
      "grad_norm": 2.7447550296783447,
      "learning_rate": 0.00014877365402315987,
      "loss": 0.7937,
      "step": 1600
    },
    {
      "epoch": 12.03021718602455,
      "eval_loss": 17.463199615478516,
      "eval_perplexity": 38385856.0,
      "eval_runtime": 21.2641,
      "eval_samples_per_second": 2.351,
      "eval_steps_per_second": 1.176,
      "step": 1600
    },
    {
      "epoch": 12.10576015108593,
      "grad_norm": 2.924673557281494,
      "learning_rate": 0.0001480022456397063,
      "loss": 0.7003,
      "step": 1610
    },
    {
      "epoch": 12.181303116147308,
      "grad_norm": 3.139103889465332,
      "learning_rate": 0.0001472271074772683,
      "loss": 0.6963,
      "step": 1620
    },
    {
      "epoch": 12.256846081208687,
      "grad_norm": 2.879657030105591,
      "learning_rate": 0.00014644829976415366,
      "loss": 0.7062,
      "step": 1630
    },
    {
      "epoch": 12.332389046270066,
      "grad_norm": 2.8534646034240723,
      "learning_rate": 0.0001456658830137947,
      "loss": 0.717,
      "step": 1640
    },
    {
      "epoch": 12.407932011331445,
      "grad_norm": 2.918935537338257,
      "learning_rate": 0.00014487991802004623,
      "loss": 0.7118,
      "step": 1650
    },
    {
      "epoch": 12.483474976392824,
      "grad_norm": 2.835782527923584,
      "learning_rate": 0.00014409046585246192,
      "loss": 0.7355,
      "step": 1660
    },
    {
      "epoch": 12.559017941454202,
      "grad_norm": 2.8041412830352783,
      "learning_rate": 0.0001432975878515492,
      "loss": 0.7213,
      "step": 1670
    },
    {
      "epoch": 12.634560906515581,
      "grad_norm": 2.765317440032959,
      "learning_rate": 0.000142501345624003,
      "loss": 0.7262,
      "step": 1680
    },
    {
      "epoch": 12.71010387157696,
      "grad_norm": 3.113581657409668,
      "learning_rate": 0.00014170180103791906,
      "loss": 0.7418,
      "step": 1690
    },
    {
      "epoch": 12.785646836638339,
      "grad_norm": 2.868793487548828,
      "learning_rate": 0.0001408990162179866,
      "loss": 0.7513,
      "step": 1700
    },
    {
      "epoch": 12.785646836638339,
      "eval_loss": 17.492502212524414,
      "eval_perplexity": 39527304.0,
      "eval_runtime": 21.1552,
      "eval_samples_per_second": 2.363,
      "eval_steps_per_second": 1.182,
      "step": 1700
    },
    {
      "epoch": 12.861189801699716,
      "grad_norm": 3.151947021484375,
      "learning_rate": 0.00014009305354066137,
      "loss": 0.7549,
      "step": 1710
    },
    {
      "epoch": 12.936732766761095,
      "grad_norm": 3.1313674449920654,
      "learning_rate": 0.00013928397562931895,
      "loss": 0.7695,
      "step": 1720
    },
    {
      "epoch": 13.007554296506138,
      "grad_norm": 2.6238391399383545,
      "learning_rate": 0.0001384718453493888,
      "loss": 0.7479,
      "step": 1730
    },
    {
      "epoch": 13.083097261567517,
      "grad_norm": 2.683997631072998,
      "learning_rate": 0.00013765672580346987,
      "loss": 0.5983,
      "step": 1740
    },
    {
      "epoch": 13.158640226628895,
      "grad_norm": 3.0450050830841064,
      "learning_rate": 0.0001368386803264272,
      "loss": 0.6321,
      "step": 1750
    },
    {
      "epoch": 13.234183191690274,
      "grad_norm": 3.387112617492676,
      "learning_rate": 0.00013601777248047105,
      "loss": 0.6227,
      "step": 1760
    },
    {
      "epoch": 13.309726156751653,
      "grad_norm": 2.9817769527435303,
      "learning_rate": 0.00013519406605021797,
      "loss": 0.6364,
      "step": 1770
    },
    {
      "epoch": 13.385269121813032,
      "grad_norm": 2.804859161376953,
      "learning_rate": 0.00013436762503773471,
      "loss": 0.6446,
      "step": 1780
    },
    {
      "epoch": 13.46081208687441,
      "grad_norm": 3.191602945327759,
      "learning_rate": 0.00013353851365756548,
      "loss": 0.6431,
      "step": 1790
    },
    {
      "epoch": 13.53635505193579,
      "grad_norm": 3.649190902709961,
      "learning_rate": 0.00013270679633174218,
      "loss": 0.6662,
      "step": 1800
    },
    {
      "epoch": 13.53635505193579,
      "eval_loss": 17.85289192199707,
      "eval_perplexity": 56677728.0,
      "eval_runtime": 21.1269,
      "eval_samples_per_second": 2.367,
      "eval_steps_per_second": 1.183,
      "step": 1800
    },
    {
      "epoch": 13.611898016997166,
      "grad_norm": 3.009504556655884,
      "learning_rate": 0.00013187253768477894,
      "loss": 0.6739,
      "step": 1810
    },
    {
      "epoch": 13.687440982058545,
      "grad_norm": 3.0156760215759277,
      "learning_rate": 0.00013103580253865087,
      "loss": 0.6619,
      "step": 1820
    },
    {
      "epoch": 13.762983947119924,
      "grad_norm": 2.9180514812469482,
      "learning_rate": 0.00013019665590775716,
      "loss": 0.6694,
      "step": 1830
    },
    {
      "epoch": 13.838526912181303,
      "grad_norm": 2.9768991470336914,
      "learning_rate": 0.00012935516299386973,
      "loss": 0.6586,
      "step": 1840
    },
    {
      "epoch": 13.914069877242682,
      "grad_norm": 3.079853057861328,
      "learning_rate": 0.0001285113891810668,
      "loss": 0.6927,
      "step": 1850
    },
    {
      "epoch": 13.98961284230406,
      "grad_norm": 3.0957765579223633,
      "learning_rate": 0.0001276654000306527,
      "loss": 0.6758,
      "step": 1860
    },
    {
      "epoch": 14.060434372049103,
      "grad_norm": 2.869272470474243,
      "learning_rate": 0.00012681726127606376,
      "loss": 0.5729,
      "step": 1870
    },
    {
      "epoch": 14.135977337110482,
      "grad_norm": 2.904161214828491,
      "learning_rate": 0.0001259670388177606,
      "loss": 0.551,
      "step": 1880
    },
    {
      "epoch": 14.211520302171861,
      "grad_norm": 2.6944453716278076,
      "learning_rate": 0.0001251147987181079,
      "loss": 0.5677,
      "step": 1890
    },
    {
      "epoch": 14.287063267233238,
      "grad_norm": 2.9457640647888184,
      "learning_rate": 0.00012426060719624137,
      "loss": 0.5515,
      "step": 1900
    },
    {
      "epoch": 14.287063267233238,
      "eval_loss": 18.0418758392334,
      "eval_perplexity": 68467920.0,
      "eval_runtime": 20.9097,
      "eval_samples_per_second": 2.391,
      "eval_steps_per_second": 1.196,
      "step": 1900
    },
    {
      "epoch": 14.362606232294617,
      "grad_norm": 3.257413387298584,
      "learning_rate": 0.0001234045306229222,
      "loss": 0.5662,
      "step": 1910
    },
    {
      "epoch": 14.438149197355996,
      "grad_norm": 3.1991424560546875,
      "learning_rate": 0.00012254663551538046,
      "loss": 0.5761,
      "step": 1920
    },
    {
      "epoch": 14.513692162417374,
      "grad_norm": 2.963386058807373,
      "learning_rate": 0.00012168698853214629,
      "loss": 0.5903,
      "step": 1930
    },
    {
      "epoch": 14.589235127478753,
      "grad_norm": 3.0313403606414795,
      "learning_rate": 0.00012082565646787092,
      "loss": 0.5871,
      "step": 1940
    },
    {
      "epoch": 14.664778092540132,
      "grad_norm": 2.9727020263671875,
      "learning_rate": 0.00011996270624813642,
      "loss": 0.5853,
      "step": 1950
    },
    {
      "epoch": 14.740321057601511,
      "grad_norm": 3.147818088531494,
      "learning_rate": 0.00011909820492425574,
      "loss": 0.5952,
      "step": 1960
    },
    {
      "epoch": 14.81586402266289,
      "grad_norm": 3.0386760234832764,
      "learning_rate": 0.00011823221966806277,
      "loss": 0.5841,
      "step": 1970
    },
    {
      "epoch": 14.891406987724269,
      "grad_norm": 3.345691680908203,
      "learning_rate": 0.00011736481776669306,
      "loss": 0.6184,
      "step": 1980
    },
    {
      "epoch": 14.966949952785647,
      "grad_norm": 3.2637338638305664,
      "learning_rate": 0.00011649606661735561,
      "loss": 0.5984,
      "step": 1990
    },
    {
      "epoch": 15.037771482530689,
      "grad_norm": 2.850309133529663,
      "learning_rate": 0.00011562603372209615,
      "loss": 0.5615,
      "step": 2000
    },
    {
      "epoch": 15.037771482530689,
      "eval_loss": 18.087072372436523,
      "eval_perplexity": 71633424.0,
      "eval_runtime": 21.2138,
      "eval_samples_per_second": 2.357,
      "eval_steps_per_second": 1.178,
      "step": 2000
    },
    {
      "epoch": 15.113314447592067,
      "grad_norm": 3.114933967590332,
      "learning_rate": 0.00011475478668255222,
      "loss": 0.4882,
      "step": 2010
    },
    {
      "epoch": 15.188857412653446,
      "grad_norm": 3.2622499465942383,
      "learning_rate": 0.00011388239319470036,
      "loss": 0.4955,
      "step": 2020
    },
    {
      "epoch": 15.264400377714825,
      "grad_norm": 2.77292537689209,
      "learning_rate": 0.00011300892104359634,
      "loss": 0.5193,
      "step": 2030
    },
    {
      "epoch": 15.339943342776204,
      "grad_norm": 3.2197248935699463,
      "learning_rate": 0.0001121344380981082,
      "loss": 0.5192,
      "step": 2040
    },
    {
      "epoch": 15.415486307837583,
      "grad_norm": 3.0011472702026367,
      "learning_rate": 0.00011125901230564271,
      "loss": 0.5042,
      "step": 2050
    },
    {
      "epoch": 15.491029272898961,
      "grad_norm": 3.3307719230651855,
      "learning_rate": 0.00011038271168686603,
      "loss": 0.5204,
      "step": 2060
    },
    {
      "epoch": 15.56657223796034,
      "grad_norm": 3.4559526443481445,
      "learning_rate": 0.00010950560433041826,
      "loss": 0.521,
      "step": 2070
    },
    {
      "epoch": 15.642115203021719,
      "grad_norm": 3.1627402305603027,
      "learning_rate": 0.00010862775838762332,
      "loss": 0.5291,
      "step": 2080
    },
    {
      "epoch": 15.717658168083098,
      "grad_norm": 3.236560583114624,
      "learning_rate": 0.0001077492420671931,
      "loss": 0.5262,
      "step": 2090
    },
    {
      "epoch": 15.793201133144477,
      "grad_norm": 3.20062518119812,
      "learning_rate": 0.0001068701236299281,
      "loss": 0.537,
      "step": 2100
    },
    {
      "epoch": 15.793201133144477,
      "eval_loss": 18.279403686523438,
      "eval_perplexity": 86824872.0,
      "eval_runtime": 21.2899,
      "eval_samples_per_second": 2.349,
      "eval_steps_per_second": 1.174,
      "step": 2100
    },
    {
      "epoch": 15.868744098205855,
      "grad_norm": 3.5802700519561768,
      "learning_rate": 0.0001059904713834133,
      "loss": 0.5423,
      "step": 2110
    },
    {
      "epoch": 15.944287063267232,
      "grad_norm": 3.1492726802825928,
      "learning_rate": 0.00010511035367671056,
      "loss": 0.5288,
      "step": 2120
    },
    {
      "epoch": 16.015108593012275,
      "grad_norm": 2.714109182357788,
      "learning_rate": 0.00010422983889504831,
      "loss": 0.5411,
      "step": 2130
    },
    {
      "epoch": 16.090651558073656,
      "grad_norm": 2.705477714538574,
      "learning_rate": 0.00010334899545450753,
      "loss": 0.4337,
      "step": 2140
    },
    {
      "epoch": 16.166194523135033,
      "grad_norm": 2.776242256164551,
      "learning_rate": 0.00010246789179670611,
      "loss": 0.4369,
      "step": 2150
    },
    {
      "epoch": 16.24173748819641,
      "grad_norm": 2.9115960597991943,
      "learning_rate": 0.00010158659638348081,
      "loss": 0.4439,
      "step": 2160
    },
    {
      "epoch": 16.31728045325779,
      "grad_norm": 3.2022228240966797,
      "learning_rate": 0.00010070517769156782,
      "loss": 0.4551,
      "step": 2170
    },
    {
      "epoch": 16.392823418319168,
      "grad_norm": 3.0557031631469727,
      "learning_rate": 9.982370420728212e-05,
      "loss": 0.4653,
      "step": 2180
    },
    {
      "epoch": 16.46836638338055,
      "grad_norm": 3.0696566104888916,
      "learning_rate": 9.894224442119607e-05,
      "loss": 0.4639,
      "step": 2190
    },
    {
      "epoch": 16.543909348441925,
      "grad_norm": 3.0486443042755127,
      "learning_rate": 9.806086682281758e-05,
      "loss": 0.4658,
      "step": 2200
    },
    {
      "epoch": 16.543909348441925,
      "eval_loss": 18.33244514465332,
      "eval_perplexity": 91554512.0,
      "eval_runtime": 20.9859,
      "eval_samples_per_second": 2.383,
      "eval_steps_per_second": 1.191,
      "step": 2200
    },
    {
      "epoch": 16.619452313503306,
      "grad_norm": 2.9316956996917725,
      "learning_rate": 9.717963989526869e-05,
      "loss": 0.4693,
      "step": 2210
    },
    {
      "epoch": 16.694995278564683,
      "grad_norm": 3.2640671730041504,
      "learning_rate": 9.629863210996419e-05,
      "loss": 0.4958,
      "step": 2220
    },
    {
      "epoch": 16.770538243626063,
      "grad_norm": 3.373999834060669,
      "learning_rate": 9.541791192129164e-05,
      "loss": 0.4924,
      "step": 2230
    },
    {
      "epoch": 16.84608120868744,
      "grad_norm": 3.3339266777038574,
      "learning_rate": 9.453754776129218e-05,
      "loss": 0.4826,
      "step": 2240
    },
    {
      "epoch": 16.92162417374882,
      "grad_norm": 3.2325947284698486,
      "learning_rate": 9.365760803434355e-05,
      "loss": 0.4751,
      "step": 2250
    },
    {
      "epoch": 16.997167138810198,
      "grad_norm": 3.2654664516448975,
      "learning_rate": 9.277816111184503e-05,
      "loss": 0.4849,
      "step": 2260
    },
    {
      "epoch": 17.06798866855524,
      "grad_norm": 2.7017595767974854,
      "learning_rate": 9.189927532690481e-05,
      "loss": 0.399,
      "step": 2270
    },
    {
      "epoch": 17.143531633616618,
      "grad_norm": 2.7032179832458496,
      "learning_rate": 9.102101896903084e-05,
      "loss": 0.3953,
      "step": 2280
    },
    {
      "epoch": 17.219074598678,
      "grad_norm": 2.9260807037353516,
      "learning_rate": 9.01434602788244e-05,
      "loss": 0.4021,
      "step": 2290
    },
    {
      "epoch": 17.294617563739376,
      "grad_norm": 2.9759058952331543,
      "learning_rate": 8.926666744267793e-05,
      "loss": 0.4097,
      "step": 2300
    },
    {
      "epoch": 17.294617563739376,
      "eval_loss": 18.53432273864746,
      "eval_perplexity": 112035096.0,
      "eval_runtime": 21.1082,
      "eval_samples_per_second": 2.369,
      "eval_steps_per_second": 1.184,
      "step": 2300
    },
    {
      "epoch": 17.370160528800756,
      "grad_norm": 3.0607948303222656,
      "learning_rate": 8.839070858747697e-05,
      "loss": 0.4138,
      "step": 2310
    },
    {
      "epoch": 17.445703493862133,
      "grad_norm": 2.916325330734253,
      "learning_rate": 8.751565177530669e-05,
      "loss": 0.4165,
      "step": 2320
    },
    {
      "epoch": 17.521246458923514,
      "grad_norm": 2.9413063526153564,
      "learning_rate": 8.664156499816337e-05,
      "loss": 0.4184,
      "step": 2330
    },
    {
      "epoch": 17.59678942398489,
      "grad_norm": 3.2266488075256348,
      "learning_rate": 8.57685161726715e-05,
      "loss": 0.4295,
      "step": 2340
    },
    {
      "epoch": 17.67233238904627,
      "grad_norm": 3.0632832050323486,
      "learning_rate": 8.489657313480663e-05,
      "loss": 0.4313,
      "step": 2350
    },
    {
      "epoch": 17.74787535410765,
      "grad_norm": 3.1567256450653076,
      "learning_rate": 8.402580363462451e-05,
      "loss": 0.4351,
      "step": 2360
    },
    {
      "epoch": 17.82341831916903,
      "grad_norm": 2.93239426612854,
      "learning_rate": 8.315627533099696e-05,
      "loss": 0.4304,
      "step": 2370
    },
    {
      "epoch": 17.898961284230406,
      "grad_norm": 3.132978916168213,
      "learning_rate": 8.228805578635456e-05,
      "loss": 0.4319,
      "step": 2380
    },
    {
      "epoch": 17.974504249291783,
      "grad_norm": 3.302231550216675,
      "learning_rate": 8.142121246143738e-05,
      "loss": 0.4352,
      "step": 2390
    },
    {
      "epoch": 18.045325779036826,
      "grad_norm": 2.74232816696167,
      "learning_rate": 8.055581271005292e-05,
      "loss": 0.4015,
      "step": 2400
    },
    {
      "epoch": 18.045325779036826,
      "eval_loss": 18.52897071838379,
      "eval_perplexity": 111437080.0,
      "eval_runtime": 21.5447,
      "eval_samples_per_second": 2.321,
      "eval_steps_per_second": 1.16,
      "step": 2400
    },
    {
      "epoch": 18.120868744098207,
      "grad_norm": 2.7212345600128174,
      "learning_rate": 7.969192377384299e-05,
      "loss": 0.3548,
      "step": 2410
    },
    {
      "epoch": 18.196411709159584,
      "grad_norm": 2.6272706985473633,
      "learning_rate": 7.882961277705895e-05,
      "loss": 0.3584,
      "step": 2420
    },
    {
      "epoch": 18.271954674220964,
      "grad_norm": 3.069793701171875,
      "learning_rate": 7.796894672134594e-05,
      "loss": 0.3698,
      "step": 2430
    },
    {
      "epoch": 18.34749763928234,
      "grad_norm": 2.6169657707214355,
      "learning_rate": 7.710999248053722e-05,
      "loss": 0.3685,
      "step": 2440
    },
    {
      "epoch": 18.423040604343722,
      "grad_norm": 2.674267292022705,
      "learning_rate": 7.62528167954578e-05,
      "loss": 0.3729,
      "step": 2450
    },
    {
      "epoch": 18.4985835694051,
      "grad_norm": 2.9345624446868896,
      "learning_rate": 7.539748626873866e-05,
      "loss": 0.378,
      "step": 2460
    },
    {
      "epoch": 18.574126534466476,
      "grad_norm": 2.9333817958831787,
      "learning_rate": 7.454406735964199e-05,
      "loss": 0.3941,
      "step": 2470
    },
    {
      "epoch": 18.649669499527857,
      "grad_norm": 3.0046920776367188,
      "learning_rate": 7.369262637889688e-05,
      "loss": 0.3921,
      "step": 2480
    },
    {
      "epoch": 18.725212464589234,
      "grad_norm": 3.250401735305786,
      "learning_rate": 7.28432294835474e-05,
      "loss": 0.3833,
      "step": 2490
    },
    {
      "epoch": 18.800755429650614,
      "grad_norm": 2.8614649772644043,
      "learning_rate": 7.199594267181194e-05,
      "loss": 0.3929,
      "step": 2500
    },
    {
      "epoch": 18.800755429650614,
      "eval_loss": 18.61429786682129,
      "eval_perplexity": 121363152.0,
      "eval_runtime": 21.1909,
      "eval_samples_per_second": 2.36,
      "eval_steps_per_second": 1.18,
      "step": 2500
    },
    {
      "epoch": 18.87629839471199,
      "grad_norm": 3.0179479122161865,
      "learning_rate": 7.115083177795507e-05,
      "loss": 0.3894,
      "step": 2510
    },
    {
      "epoch": 18.951841359773372,
      "grad_norm": 2.9268834590911865,
      "learning_rate": 7.030796246717255e-05,
      "loss": 0.3949,
      "step": 2520
    },
    {
      "epoch": 19.022662889518415,
      "grad_norm": 2.2573156356811523,
      "learning_rate": 6.94674002304887e-05,
      "loss": 0.3842,
      "step": 2530
    },
    {
      "epoch": 19.098205854579792,
      "grad_norm": 2.8505427837371826,
      "learning_rate": 6.862921037966815e-05,
      "loss": 0.3227,
      "step": 2540
    },
    {
      "epoch": 19.173748819641173,
      "grad_norm": 2.915236711502075,
      "learning_rate": 6.779345804214088e-05,
      "loss": 0.3383,
      "step": 2550
    },
    {
      "epoch": 19.24929178470255,
      "grad_norm": 2.529571771621704,
      "learning_rate": 6.696020815594177e-05,
      "loss": 0.335,
      "step": 2560
    },
    {
      "epoch": 19.324834749763927,
      "grad_norm": 2.9685442447662354,
      "learning_rate": 6.612952546466506e-05,
      "loss": 0.3351,
      "step": 2570
    },
    {
      "epoch": 19.400377714825307,
      "grad_norm": 2.72408127784729,
      "learning_rate": 6.530147451243377e-05,
      "loss": 0.3423,
      "step": 2580
    },
    {
      "epoch": 19.475920679886684,
      "grad_norm": 2.5194435119628906,
      "learning_rate": 6.447611963888442e-05,
      "loss": 0.3477,
      "step": 2590
    },
    {
      "epoch": 19.551463644948065,
      "grad_norm": 3.0387072563171387,
      "learning_rate": 6.36535249741681e-05,
      "loss": 0.3472,
      "step": 2600
    },
    {
      "epoch": 19.551463644948065,
      "eval_loss": 18.639089584350586,
      "eval_perplexity": 124409560.0,
      "eval_runtime": 20.902,
      "eval_samples_per_second": 2.392,
      "eval_steps_per_second": 1.196,
      "step": 2600
    },
    {
      "epoch": 19.627006610009442,
      "grad_norm": 2.944857120513916,
      "learning_rate": 6.283375443396726e-05,
      "loss": 0.3538,
      "step": 2610
    },
    {
      "epoch": 19.702549575070822,
      "grad_norm": 2.9698240756988525,
      "learning_rate": 6.201687171452973e-05,
      "loss": 0.3518,
      "step": 2620
    },
    {
      "epoch": 19.7780925401322,
      "grad_norm": 2.8388054370880127,
      "learning_rate": 6.120294028771938e-05,
      "loss": 0.3624,
      "step": 2630
    },
    {
      "epoch": 19.85363550519358,
      "grad_norm": 3.037086248397827,
      "learning_rate": 6.039202339608432e-05,
      "loss": 0.3527,
      "step": 2640
    },
    {
      "epoch": 19.929178470254957,
      "grad_norm": 2.5360732078552246,
      "learning_rate": 5.958418404794306e-05,
      "loss": 0.3611,
      "step": 2650
    },
    {
      "epoch": 20.0,
      "grad_norm": 4.540112495422363,
      "learning_rate": 5.877948501248858e-05,
      "loss": 0.3632,
      "step": 2660
    },
    {
      "epoch": 20.075542965061377,
      "grad_norm": 2.609049081802368,
      "learning_rate": 5.797798881491138e-05,
      "loss": 0.3029,
      "step": 2670
    },
    {
      "epoch": 20.151085930122758,
      "grad_norm": 2.7850677967071533,
      "learning_rate": 5.7179757731541164e-05,
      "loss": 0.3076,
      "step": 2680
    },
    {
      "epoch": 20.226628895184135,
      "grad_norm": 2.6210126876831055,
      "learning_rate": 5.638485378500786e-05,
      "loss": 0.3058,
      "step": 2690
    },
    {
      "epoch": 20.302171860245515,
      "grad_norm": 2.502234697341919,
      "learning_rate": 5.559333873942259e-05,
      "loss": 0.3051,
      "step": 2700
    },
    {
      "epoch": 20.302171860245515,
      "eval_loss": 18.778162002563477,
      "eval_perplexity": 142972384.0,
      "eval_runtime": 23.8809,
      "eval_samples_per_second": 2.094,
      "eval_steps_per_second": 1.047,
      "step": 2700
    },
    {
      "epoch": 20.377714825306892,
      "grad_norm": 2.882908821105957,
      "learning_rate": 5.4805274095578626e-05,
      "loss": 0.3118,
      "step": 2710
    },
    {
      "epoch": 20.453257790368273,
      "grad_norm": 2.828284502029419,
      "learning_rate": 5.402072108617258e-05,
      "loss": 0.3182,
      "step": 2720
    },
    {
      "epoch": 20.52880075542965,
      "grad_norm": 2.703054666519165,
      "learning_rate": 5.3239740671046864e-05,
      "loss": 0.3202,
      "step": 2730
    },
    {
      "epoch": 20.60434372049103,
      "grad_norm": 2.645190715789795,
      "learning_rate": 5.24623935324529e-05,
      "loss": 0.3159,
      "step": 2740
    },
    {
      "epoch": 20.679886685552407,
      "grad_norm": 2.6595423221588135,
      "learning_rate": 5.168874007033615e-05,
      "loss": 0.3135,
      "step": 2750
    },
    {
      "epoch": 20.755429650613788,
      "grad_norm": 2.938349723815918,
      "learning_rate": 5.091884039764321e-05,
      "loss": 0.3209,
      "step": 2760
    },
    {
      "epoch": 20.830972615675165,
      "grad_norm": 2.9772872924804688,
      "learning_rate": 5.0152754335650696e-05,
      "loss": 0.3219,
      "step": 2770
    },
    {
      "epoch": 20.906515580736546,
      "grad_norm": 2.8995237350463867,
      "learning_rate": 4.9390541409317504e-05,
      "loss": 0.328,
      "step": 2780
    },
    {
      "epoch": 20.982058545797923,
      "grad_norm": 3.1665773391723633,
      "learning_rate": 4.8632260842659393e-05,
      "loss": 0.3303,
      "step": 2790
    },
    {
      "epoch": 21.052880075542966,
      "grad_norm": 2.373162269592285,
      "learning_rate": 4.787797155414742e-05,
      "loss": 0.2928,
      "step": 2800
    },
    {
      "epoch": 21.052880075542966,
      "eval_loss": 18.784652709960938,
      "eval_perplexity": 143903392.0,
      "eval_runtime": 21.2402,
      "eval_samples_per_second": 2.354,
      "eval_steps_per_second": 1.177,
      "step": 2800
    },
    {
      "epoch": 21.128423040604343,
      "grad_norm": 2.9362094402313232,
      "learning_rate": 4.712773215213006e-05,
      "loss": 0.282,
      "step": 2810
    },
    {
      "epoch": 21.203966005665723,
      "grad_norm": 2.268310546875,
      "learning_rate": 4.638160093027908e-05,
      "loss": 0.2762,
      "step": 2820
    },
    {
      "epoch": 21.2795089707271,
      "grad_norm": 2.7947192192077637,
      "learning_rate": 4.56396358630604e-05,
      "loss": 0.2905,
      "step": 2830
    },
    {
      "epoch": 21.35505193578848,
      "grad_norm": 2.7726075649261475,
      "learning_rate": 4.490189460122925e-05,
      "loss": 0.2832,
      "step": 2840
    },
    {
      "epoch": 21.430594900849858,
      "grad_norm": 2.609720468521118,
      "learning_rate": 4.416843446735077e-05,
      "loss": 0.2833,
      "step": 2850
    },
    {
      "epoch": 21.50613786591124,
      "grad_norm": 2.514599561691284,
      "learning_rate": 4.343931245134616e-05,
      "loss": 0.2933,
      "step": 2860
    },
    {
      "epoch": 21.581680830972616,
      "grad_norm": 2.8827760219573975,
      "learning_rate": 4.271458520606432e-05,
      "loss": 0.309,
      "step": 2870
    },
    {
      "epoch": 21.657223796033996,
      "grad_norm": 2.6216442584991455,
      "learning_rate": 4.19943090428802e-05,
      "loss": 0.3049,
      "step": 2880
    },
    {
      "epoch": 21.732766761095373,
      "grad_norm": 2.7688422203063965,
      "learning_rate": 4.127853992731913e-05,
      "loss": 0.2916,
      "step": 2890
    },
    {
      "epoch": 21.80830972615675,
      "grad_norm": 3.111152410507202,
      "learning_rate": 4.0567333474708425e-05,
      "loss": 0.3022,
      "step": 2900
    },
    {
      "epoch": 21.80830972615675,
      "eval_loss": 18.804590225219727,
      "eval_perplexity": 146801248.0,
      "eval_runtime": 21.1895,
      "eval_samples_per_second": 2.36,
      "eval_steps_per_second": 1.18,
      "step": 2900
    },
    {
      "epoch": 21.88385269121813,
      "grad_norm": 2.6438241004943848,
      "learning_rate": 3.986074494585619e-05,
      "loss": 0.2988,
      "step": 2910
    },
    {
      "epoch": 21.959395656279508,
      "grad_norm": 2.334392547607422,
      "learning_rate": 3.9158829242757245e-05,
      "loss": 0.2983,
      "step": 2920
    },
    {
      "epoch": 22.03021718602455,
      "grad_norm": 2.344820022583008,
      "learning_rate": 3.8461640904327564e-05,
      "loss": 0.285,
      "step": 2930
    },
    {
      "epoch": 22.10576015108593,
      "grad_norm": 2.536944627761841,
      "learning_rate": 3.776923410216636e-05,
      "loss": 0.2636,
      "step": 2940
    },
    {
      "epoch": 22.18130311614731,
      "grad_norm": 2.2250494956970215,
      "learning_rate": 3.708166263634699e-05,
      "loss": 0.2592,
      "step": 2950
    },
    {
      "epoch": 22.25684608120869,
      "grad_norm": 2.432305097579956,
      "learning_rate": 3.639897993123686e-05,
      "loss": 0.2686,
      "step": 2960
    },
    {
      "epoch": 22.332389046270066,
      "grad_norm": 2.6535556316375732,
      "learning_rate": 3.5721239031346066e-05,
      "loss": 0.2695,
      "step": 2970
    },
    {
      "epoch": 22.407932011331443,
      "grad_norm": 2.5329232215881348,
      "learning_rate": 3.504849259720611e-05,
      "loss": 0.2693,
      "step": 2980
    },
    {
      "epoch": 22.483474976392824,
      "grad_norm": 2.754826068878174,
      "learning_rate": 3.438079290127791e-05,
      "loss": 0.2736,
      "step": 2990
    },
    {
      "epoch": 22.5590179414542,
      "grad_norm": 2.4246156215667725,
      "learning_rate": 3.37181918238904e-05,
      "loss": 0.2777,
      "step": 3000
    },
    {
      "epoch": 22.5590179414542,
      "eval_loss": 18.8841552734375,
      "eval_perplexity": 158958752.0,
      "eval_runtime": 21.3034,
      "eval_samples_per_second": 2.347,
      "eval_steps_per_second": 1.174,
      "step": 3000
    },
    {
      "epoch": 22.63456090651558,
      "grad_norm": 2.3367676734924316,
      "learning_rate": 3.306074084920942e-05,
      "loss": 0.2751,
      "step": 3010
    },
    {
      "epoch": 22.71010387157696,
      "grad_norm": 2.4947397708892822,
      "learning_rate": 3.240849106123732e-05,
      "loss": 0.2739,
      "step": 3020
    },
    {
      "epoch": 22.78564683663834,
      "grad_norm": 2.4602324962615967,
      "learning_rate": 3.1761493139843735e-05,
      "loss": 0.2819,
      "step": 3030
    },
    {
      "epoch": 22.861189801699716,
      "grad_norm": 2.3593943119049072,
      "learning_rate": 3.111979735682779e-05,
      "loss": 0.2838,
      "step": 3040
    },
    {
      "epoch": 22.936732766761097,
      "grad_norm": 2.576571464538574,
      "learning_rate": 3.0483453572011922e-05,
      "loss": 0.2759,
      "step": 3050
    },
    {
      "epoch": 23.00755429650614,
      "grad_norm": 2.165067434310913,
      "learning_rate": 2.9852511229367865e-05,
      "loss": 0.2832,
      "step": 3060
    },
    {
      "epoch": 23.083097261567517,
      "grad_norm": 2.1949450969696045,
      "learning_rate": 2.922701935317481e-05,
      "loss": 0.2474,
      "step": 3070
    },
    {
      "epoch": 23.158640226628894,
      "grad_norm": 2.4947617053985596,
      "learning_rate": 2.8607026544210114e-05,
      "loss": 0.2467,
      "step": 3080
    },
    {
      "epoch": 23.234183191690274,
      "grad_norm": 2.357998847961426,
      "learning_rate": 2.7992580975973136e-05,
      "loss": 0.2567,
      "step": 3090
    },
    {
      "epoch": 23.30972615675165,
      "grad_norm": 2.3045053482055664,
      "learning_rate": 2.7383730390942076e-05,
      "loss": 0.256,
      "step": 3100
    },
    {
      "epoch": 23.30972615675165,
      "eval_loss": 18.977819442749023,
      "eval_perplexity": 174567040.0,
      "eval_runtime": 21.1789,
      "eval_samples_per_second": 2.361,
      "eval_steps_per_second": 1.18,
      "step": 3100
    },
    {
      "epoch": 23.38526912181303,
      "grad_norm": 2.3114490509033203,
      "learning_rate": 2.678052209686448e-05,
      "loss": 0.2599,
      "step": 3110
    },
    {
      "epoch": 23.46081208687441,
      "grad_norm": 2.6054227352142334,
      "learning_rate": 2.618300296308135e-05,
      "loss": 0.2546,
      "step": 3120
    },
    {
      "epoch": 23.53635505193579,
      "grad_norm": 2.3901994228363037,
      "learning_rate": 2.5591219416885336e-05,
      "loss": 0.2669,
      "step": 3130
    },
    {
      "epoch": 23.611898016997166,
      "grad_norm": 2.898432731628418,
      "learning_rate": 2.500521743991342e-05,
      "loss": 0.2568,
      "step": 3140
    },
    {
      "epoch": 23.687440982058547,
      "grad_norm": 2.475590229034424,
      "learning_rate": 2.4425042564574184e-05,
      "loss": 0.2626,
      "step": 3150
    },
    {
      "epoch": 23.762983947119924,
      "grad_norm": 2.5189201831817627,
      "learning_rate": 2.385073987050974e-05,
      "loss": 0.26,
      "step": 3160
    },
    {
      "epoch": 23.838526912181305,
      "grad_norm": 2.449498176574707,
      "learning_rate": 2.3282353981093296e-05,
      "loss": 0.2502,
      "step": 3170
    },
    {
      "epoch": 23.91406987724268,
      "grad_norm": 2.6211235523223877,
      "learning_rate": 2.2719929059961698e-05,
      "loss": 0.2651,
      "step": 3180
    },
    {
      "epoch": 23.989612842304062,
      "grad_norm": 2.5357043743133545,
      "learning_rate": 2.2163508807583998e-05,
      "loss": 0.2594,
      "step": 3190
    },
    {
      "epoch": 24.0604343720491,
      "grad_norm": 2.105513334274292,
      "learning_rate": 2.161313645786599e-05,
      "loss": 0.2336,
      "step": 3200
    },
    {
      "epoch": 24.0604343720491,
      "eval_loss": 18.947126388549805,
      "eval_perplexity": 169290448.0,
      "eval_runtime": 21.305,
      "eval_samples_per_second": 2.347,
      "eval_steps_per_second": 1.173,
      "step": 3200
    }
  ],
  "logging_steps": 10,
  "max_steps": 3960,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5871832472158208e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
