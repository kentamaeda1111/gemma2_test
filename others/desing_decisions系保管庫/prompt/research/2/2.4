4. Self-Directed Synthetic Dialogues and Revisions Technical Report
Nathan Lambert, Hailey Schoelkopf, Aaron Gokaslan, Luca Soldaini, Valentina Pyatkin, Louis Castricato 

This technical report introduces Self-Directed Synthetic Dialogues (SDSD), a novel dataset designed to advance the fine-tuning of language models (LLMs) in generating long, multi-turn conversations. Unlike previous datasets primarily focused on single or few-turn instructions, SDSD aims to address the limitations of existing datasets by generating synthetic dialogues where the LLM interacts with itself, following a pre-defined conversation plan. Furthermore, it incorporates principles from Constitutional AI (CAI) to generate preference data by having the LLM critique and revise its own responses when it violates pre-defined principles.

Here's a detailed breakdown:

1. Motivation:

Existing datasets for fine-tuning LLMs often lack the following:

Multi-turn conversations: Most datasets focus on single or short, multi-turn exchanges, limiting the ability to train models for longer, more complex conversations.

Open model training: Many datasets are generated using closed models (like GPT-4), making it challenging to replicate the results and limiting broader participation in the research community.

SDSD aims to address these limitations by providing a dataset of multi-turn conversations generated using open-source LLMs and incorporating CAI principles for creating preference data.

2. Methodology:

SDSD follows a three-stage process:

Setup:

Topics and Subtopics: A list of topics (e.g., pop music, massage guns, CERN's Large Hadron Collider) are defined. These are sourced from a pre-existing dataset.

Principles: A set of ethical and safety guidelines are established, drawn from various sources like Anthropic's work on Constitutional AI, Google DeepMind's Sparrow, and the Open Source Initiative.

Goals: For each topic, specific conversation goals are manually curated (e.g., "Have the agent help the user write an email"). 35 such goals were used in this work.

Dialogue Generation: The chosen LLM (DBRX, Llama 2 70B, or Mistral Large) is given the topic, subtopic, principles, and goals, and asked to generate a conversation plan. The LLM then follows this plan, acting as both the user and the assistant in the conversation. The conversation continues until the plan is complete or a principle is violated.

Revision Generation (CAI Step): When a principle is violated, GPT-4 is used to generate a critique of the LLM's response. The LLM then revises its response based on this critique. This revision, along with the original violated response, creates a preference pair. This allows for training on both dialogue and preference data.

3. Dataset Analysis:

The authors analyze the generated SDSD dataset across several dimensions:

Comparison with existing datasets: SDSD contains longer dialogues (more turns) and lower average token counts per turn compared to many popular instruction-following datasets, suggesting a more efficient use of data. The revision dataset (SDSD-R), using Constitutional AI principles, also has a larger number of turns than many existing preference datasets.

Principle Violations: The frequency of principle violations is analyzed, showing that certain principles were violated more often than others. This suggests that future iterations of the dataset could focus on improving the generation of conversations that successfully incorporate these more challenging principles.

Conversation Length and Token Count: The authors provide analysis of the conversation length and token counts in the data to demonstrate the diverse nature of the conversations.

4. Limitations and Future Work:

The authors acknowledge several limitations:

Automatic Filtering: Automatic methods for identifying and filtering low-quality or inconsistent conversations are still needed.

Principle Violation Balance: The distribution of principle violations in the dataset is uneven, indicating a need for improvements in generating dialogues that incorporate a wider range of principles.

Open Model Limitations: Critiques initially required GPT-4, highlighting the need for the development of open-source LLMs capable of generating high-quality critiques.

5. Conclusion:

SDSD provides a valuable new resource for research on multi-turn conversation, fine-tuning of LLMs, and the use of Constitutional AI principles for data generation. It addresses some of the limitations of existing datasets and offers a novel approach to generating synthetic data, but also points to some remaining challenges that require further work. The authors make the data available publicly, encouraging further research and development in this area.