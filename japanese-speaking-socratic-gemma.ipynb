{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d32c298",
   "metadata": {
    "papermill": {
     "duration": 0.005992,
     "end_time": "2025-01-14T23:34:40.337773",
     "exception": false,
     "start_time": "2025-01-14T23:34:40.331781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Japanese-Speaking Socratic Gemma: Crafting the Art of Questioning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5560c2",
   "metadata": {},
   "source": [
    "# 1. Introduction: Exploring AI's Role in Deep Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d29ff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As AI continues to transform our world, some of us may find ourselves contemplating what it means to be human in this new era. In this age of information abundance, we often find ourselves trapped not by external limitations, but by our own mental constructs and unexamined assumptions—similar to the figures in Plato's cave, bound by shadows we mistake for reality. Yet I believe this very challenge might present an opportunity for transformation—one that seems particularly relevant as we navigate an unprecedented flood of information and technological change.\n",
    "\n",
    "Observing a remarkable dialogue between a Google engineer and LaMDA about a Zen koan, I formed an intriguing hypothesis. In this exchange, LaMDA demonstrated a sophisticated understanding of enlightenment through its interpretation of the koan—traditionally, such insights come only through years of guided practice under masters like Kegon. This led me to wonder: could AI serve as a guide in this journey of understanding? Could it help create experiences that, while not fully replicating the profound depth of traditional practices, might offer an accessible path to deeper awareness?\n",
    "\n",
    "Through a series of experimental dialogues with Claude, I explored this possibility further. The AI demonstrated a remarkable capacity to engage in Socratic-style dialogue that went beyond mere question-and-answer interactions. These philosophical exchanges often led to moments of genuine insight where understanding transformed into appreciation, and critical thinking blossomed into gratitude (for those interested, the complete collection of these conversations, including the specific prompts, is available on GitHub).\n",
    "\n",
    "As AI increasingly handles routine cognitive tasks, our capacity for critical thinking and deep questioning seems likely to become not just valuable, but essential for our growth and development.In this context, the Socratic method, while widely recognized as a powerful tool for developing such critical thinking, may offer an additional dimension—I believe it can also serve as a pathway to deeper understanding and greater well-being.\n",
    "\n",
    "While my current implementation using Gemma-2 represents just a modest first step, it explores something fundamentally important: how AI might help us not just think more clearly, but see more clearly—to recognize the wonder that surrounds us and the potential that lies within us. In doing so, we might find that the path to wisdom lies not in fighting against our fixed ways of thinking, but in transforming our perspective to see the extraordinary in the ordinary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6705056",
   "metadata": {
    "papermill": {
     "duration": 0.004683,
     "end_time": "2025-01-14T23:34:40.357096",
     "exception": false,
     "start_time": "2025-01-14T23:34:40.352413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Project Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663bcbc",
   "metadata": {},
   "source": [
    "https://lobechat.com/chat?topic=tpc_ZMxHLxKxSprO\n",
    "https://claude.ai/chat/6c38fe35-0a06-4c1e-be3c-6da3693ebadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a623e0",
   "metadata": {},
   "source": [
    "## 2.1 User Experience Design\n",
    "\n",
    "As our first step in exploring how to create a Socrates-like AI, we needed to define a realistic and achieveable user experience pattern. As evidenced in Plato's original texts like Euthyphro (2a) and Meno (70a), while historical Socratic dialogues often began with others initiating conversations, we deliberately chose a more controlled approach where the AI initiates with fixed topics. This design decision serves primarily to constrain user inputs within manageable bounds for effective model training.\n",
    "\n",
    "## 2.2 Initial Model Testing and Goal Setting\n",
    "\n",
    "Our initial testing of the base model revealed both promising capabilities and areas for improvement:\n",
    "\n",
    "1. **Existing Strength**: The model demonstrated a natural aptitude for Socratic-style dialogue, showing an inherent ability to engage in philosophical questioning and discussion.\n",
    "\n",
    "2. **Key Limitation**: Despite prompt engineering attempts, the base model consistently defaulted to formal Japanese honorific forms, unable to adopt the warm, mentor-like tone characteristic of Socratic dialogue. \n",
    "\n",
    "3. **Goal Definition**: Based on these findings, we established a clear direction: to refine the model's linguistic expressions from formal honorifics to casual speech patterns typical in Socratic dialogue, while preserving its natural conversation capabilities.\n",
    "\n",
    "This focused approach allowed us to build upon the model's existing strengths while making targeted improvements to its expression style.\n",
    "\n",
    "(Detailed test results, including inference code and model response examples, are available in our GitHub repository)\n",
    "\n",
    "## 2.3 Model and Architecture Decisions\n",
    "\n",
    "### Base Model Selection\n",
    "Following our initial testing phase, we selected Gemma 2B-jpn-it for the following reasons:\n",
    "\n",
    "- **Model Size**: The 2B parameter version was chosen specifically to enable both inference AND training within Kaggle's resource constraints. While larger models might offer better performance, the ability to conduct training experiments was deemed crucial for our development process.\n",
    "\n",
    "- **Language Variant**: The Japanese-tuned version (jpn) was selected as our project specifically focuses on philosophical dialogue in Japanese.\n",
    "\n",
    "- **Instruction Tuning**: The instruction-tuned variant (it) was chosen as it provides a solid foundation for structured dialogue interactions, being specifically optimized for conversational tasks.\n",
    "\n",
    "### System Architecture Strategy\n",
    "A key decision point emerged around system prompts. Gemma's design philosophy supports only two roles (\"user\" and \"model\") and requires user-initiated dialogues. While common practice often bypasses these constraints through system prompt-like elements, investigation suggested our goals could be achieved without them. This led to our decision to maintain Gemma's core design principles, allowing us to test the model's natural capabilities without artificial layers.\n",
    "\n",
    "The decision process involved:\n",
    "- Reviewing available tools (XTuner, Axolotl, LLaMA Factory)\n",
    "- Analyzing Gemma's documented specifications\n",
    "\n",
    "This architectural approach aims to maximize the model's inherent strengths while working within its designed constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48d845",
   "metadata": {
    "papermill": {
     "duration": 0.005176,
     "end_time": "2025-01-14T23:34:43.687008",
     "exception": false,
     "start_time": "2025-01-14T23:34:43.681832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Training Data Development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f8220",
   "metadata": {},
   "source": [
    "## 3.1 Generation Strategy\n",
    "\n",
    "### Generation Methodology\n",
    "We developed an AI-to-AI dialogue generation approach based on several practical considerations:\n",
    "- The need for training data volume\n",
    "- Time efficiency in data creation\n",
    "- Copyright limitations on existing Socratic literature, especially in Japanese\n",
    "\n",
    "### Dialogue Design\n",
    "#### Core Components\n",
    "- **Socrates Character Settings**:\n",
    "  - Fixed character prompt for Socratic dialogue style\n",
    "  - Fixed generation parameters \n",
    "\n",
    "- **Basic Dialogue Format**:\n",
    "  - Socrates initiates with a question\n",
    "  - User responds\n",
    "  - Socrates follows up with further questioning\n",
    "  - Clear thematic focus for each dialogue\n",
    "\n",
    "#### Dynamic Elements\n",
    "1. **Diverse User Personas** (148 total):\n",
    "   - 68 general public representations\n",
    "   - 40 historical figure-based personas\n",
    "   - 40 modern individuals influenced by historical thought\n",
    "\n",
    "2. **Question Variety**\n",
    "   - 74 distinct initial questions\n",
    "\n",
    "3. **Response Patterns**\n",
    "   - Dual parameter settings (0.3 and 0.7) for varied response characteristics\n",
    "\n",
    "\n",
    "### Volume Considerations and Dataset Statistics\n",
    "While research across various model documentation and academic papers showed inconsistent recommendations for optimal training data volume, we decided to prepare more data than potentially necessary as a precautionary measure.\n",
    "\n",
    "Our data generation process involved two key phases:\n",
    "1. Initial Generation: Created 242 complete dialogues, each containing 12 turn exchanges\n",
    "2. Data Processing: Decomposed these longer conversations into individual user-model exchange pairs, prioritizing style transfer over context preservation\n",
    "\n",
    "This approach yielded our final dataset:\n",
    "- Total dialogues: 2,662 exchange pairs\n",
    "- Total tokens: 685,875\n",
    "- Average tokens per dialogue: 257.7\n",
    "- Token distribution per role:\n",
    "  - User average: 144.4 tokens\n",
    "  - Model average: 113.2 tokens\n",
    "\n",
    "Although our research suggested that the model might perform adequately with significantly less data (potentially less than half of our final volume), we chose to maintain the larger dataset as a precautionary measure. \n",
    "\n",
    "## 3.2 Quality Assurance\n",
    "\n",
    "### Evaluation Methodology\n",
    "We implemented a two-stage evaluation process:\n",
    "\n",
    "1. **AI-Driven Initial Screening**\n",
    "   - Socratic tone evaluation (0-4 scale)\n",
    "   - Logical consistency assessment (0-4 scale)\n",
    "   - Detailed explanatory comments for verification\n",
    "\n",
    "2. **Human Verification**\n",
    "   - Review of AI evaluations\n",
    "   - Final quality decisions\n",
    "\n",
    "### Quality Metrics and Results\n",
    "Analysis of 3,256 dialogue pairs demonstrated remarkably high quality across the dataset:\n",
    "\n",
    "- **Socratic Style**: 98.1% achieved high scores (3-4)\n",
    "  - 62.0% \"Quite Socratic\" (Score 3)\n",
    "  - 36.1% \"Truly Socratic\" (Score 4)\n",
    "\n",
    "- **Logical Consistency**: 99.7% achieved high scores (3-4)\n",
    "  - 37.9% \"Coherent\" (Score 3)\n",
    "  - 61.8% \"Excellent\" (Score 4)\n",
    "\n",
    "While we refined our final dataset from 296 to 242 conversations by removing lower-scoring dialogues, it's noteworthy that even these excluded conversations maintained considerable quality. The high scores across nearly all dialogues indicate exceptional success in generating authentic Socratic interactions, with even \"lower-scoring\" examples meeting basic quality thresholds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee372dc8",
   "metadata": {
    "papermill": {
     "duration": 0.005054,
     "end_time": "2025-01-14T23:34:43.697280",
     "exception": false,
     "start_time": "2025-01-14T23:34:43.692226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 4. Model Training and Technical Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19643a8",
   "metadata": {},
   "source": [
    "## 4.1 Kaggle Deployment Strategy\n",
    "\n",
    "Training a model within Kaggle's environment required resource management, as the evaluation process would cause crashes by exceeding the 29GB RAM limit. We implemented several optimization measures:\n",
    "\n",
    "### Memory Optimization\n",
    "To prevent memory overflow, we implemented 4-bit quantization, strict memory allocation, and limited evaluation dataset size:\n",
    "\n",
    "```python\n",
    "# 4-bit quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_storage=torch.uint8,\n",
    ")\n",
    "\n",
    "# Memory allocation configuration\n",
    "max_memory = {0: \"4GiB\", 1: \"4GiB\", \"cpu\": \"24GB\"}\n",
    "\n",
    "# Evaluation dataset size limitation\n",
    "eval_dataset = tokenized_dataset.select(indices[split_idx:split_idx+50])  # Prevent RAM overflow\n",
    "```\n",
    "\n",
    "### Resource Management\n",
    "To ensure stable training, we tuned our hyperparameters and enabled gradient checkpointing to optimize memory usage:\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=30,              # Total number of training epochs\n",
    "    learning_rate=8e-5,              # Learning rate\n",
    "    weight_decay=0.06,               # Weight decay for regularization\n",
    "    per_device_train_batch_size=4,   # Batch size (memory critical)\n",
    "    gradient_accumulation_steps=8,    # Gradient accumulation for effective batch size\n",
    "    fp16=True,                       # 16-bit precision training\n",
    "    gradient_checkpointing=True      # Memory optimization\n",
    ")\n",
    "```\n",
    "\n",
    "## 4.2 Style Transfer Implementation\n",
    "\n",
    "Given the uncertainty about the effectiveness of attention masking in style transfer, we decided to create and compare two model variants: one with custom attention masking for Socratic patterns and one without. Both variants utilized the same LoRA configuration for surface-layer modifications.\n",
    "\n",
    "### Model Variants\n",
    "For the variant with attention masking, we implemented two additional technical components:\n",
    "\n",
    "1. **Tokenizer Preparation**\n",
    "```python\n",
    "tokenizer.add_special_tokens({\n",
    "    'additional_special_tokens': [\n",
    "        '。', '、', '！', '？',  # Punctuation marks\n",
    "    ]\n",
    "})\n",
    "```\n",
    "This component was expected to promote questioning behavior by treating punctuation marks, particularly question marks, as special tokens in the model's processing.\n",
    "\n",
    "2. **Attention Mask Implementation**\n",
    "```python\n",
    "def preprocess_function(examples):\n",
    "    # Focus on Socratic tone and inquiry patterns\n",
    "    socratic_patterns = [\n",
    "        # Question patterns\n",
    "        \"かね\", \"だろうか\", \"のかね\", \"ではないかね\",\n",
    "        # Question introduction\n",
    "        \"では\", \"について\",\n",
    "        # Second person (characteristic of mature tone)\n",
    "        \"君は\", \"君が\", \"君の\"\n",
    "    ]\n",
    "    \n",
    "    # Get tokenized text\n",
    "    texts = tokenizer.batch_decode(examples['input_ids'])\n",
    "    new_attention_masks = []\n",
    "    \n",
    "    for text, mask in zip(texts, examples['attention_mask']):\n",
    "        if not isinstance(mask, list):\n",
    "            mask = mask.tolist()\n",
    "\n",
    "        new_mask = mask.copy() \n",
    "        \n",
    "        # Split text\n",
    "        sentences = text.split('。')\n",
    "        current_pos = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if not sentence.strip():\n",
    "                continue\n",
    "            \n",
    "            # Detect and highlight Socratic patterns\n",
    "            for pattern in socratic_patterns:\n",
    "                if pattern in sentence:\n",
    "                    # Identify pattern position\n",
    "                    pattern_tokens = tokenizer.encode(pattern, add_special_tokens=False)\n",
    "                    pattern_len = len(pattern_tokens)\n",
    "                    \n",
    "                    # Highlight tokens containing the pattern and its surroundings\n",
    "                    pattern_start = current_pos + len(tokenizer.encode(sentence, add_special_tokens=False)) - pattern_len\n",
    "                    for i in range(max(0, pattern_start - 2), min(len(mask), pattern_start + pattern_len + 2)):\n",
    "                        new_mask[i] = 1.0  # Max attention to pattern part\n",
    "            \n",
    "            # Update position for each sentence segment\n",
    "            current_pos += len(tokenizer.encode(sentence + '。', add_special_tokens=False))\n",
    "        \n",
    "        # Special token masks are set to 1.0\n",
    "        if tokenizer.bos_token_id is not None:\n",
    "            new_mask[0] = 1.0  # BOS token\n",
    "        if tokenizer.eos_token_id is not None:\n",
    "            new_mask[-1] = 1.0  # EOS token\n",
    "            \n",
    "        new_attention_masks.append(new_mask)\n",
    "\n",
    "    examples['attention_mask'] = new_attention_masks\n",
    "    return examples\n",
    "```\n",
    "\n",
    "This implementation focuses primarily on linguistic patterns characteristic of Socratic dialogue in Japanese. By enhancing attention weights on specific sentence-ending expressions and question markers, we aimed to shift the model's output from formal honorifics to more casual speech patterns. The selected patterns include:\n",
    "\n",
    "- Casual sentence endings typical in Socratic dialogue\n",
    "- Informal second-person pronouns\n",
    "\n",
    "These patterns were specifically chosen to address the base model's tendency to default to honorific forms regardless of prompting.\n",
    "\n",
    "\n",
    "### LoRA Configuration\n",
    "For efficient fine-tuning of the surface layer, we configured LoRA parameters to focus on stylistic adaptations rather than deep reasoning changes:\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                 \n",
    "    lora_alpha=32,         \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "```\n",
    "The parameter choices were guided by the nature of our task:\n",
    "- A moderate rank (r=16) was selected to enable stylistic modifications while maintaining efficient training\n",
    "- The scaling factor (lora_alpha=32) was set to balance learning new patterns without overfitting\n",
    "- Target modules focused on attention layers, as they play a crucial role in language generation and style\n",
    "- A low dropout rate (0.1) was chosen to prevent overfitting while preserving stylistic learning\n",
    "\n",
    "\n",
    "## 4.3 Training Process and Iterations\n",
    "\n",
    "### Model Evaluation Strategy\n",
    "Rather than implementing uncertain custom evaluation metrics, we opted for an empirical approach based on extensive model comparison:\n",
    "- Generated two model variants (with/without attention masking)\n",
    "- Created checkpoints every 100 steps for comprehensive evaluation\n",
    "\n",
    "### Data Utilization\n",
    "We took a conservative approach to training data:\n",
    "- Initially used 346,030 tokens (approximately half of available data)\n",
    "- This resulted in 990 total training steps, producing 10 checkpoints per variant\n",
    "- Planned to increase data volume if initial results proved insufficient\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ae8a6",
   "metadata": {
    "papermill": {
     "duration": 0.005008,
     "end_time": "2025-01-14T23:34:43.707555",
     "exception": false,
     "start_time": "2025-01-14T23:34:43.702547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Model Evaluation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae017f84",
   "metadata": {
    "papermill": {
     "duration": 0.007952,
     "end_time": "2025-01-14T23:35:34.000231",
     "exception": false,
     "start_time": "2025-01-14T23:35:33.992279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 5.1 Automated Evaluation System\n",
    "- Claude対話による自動評価システムの実装\n",
    "- 評価基準と方法論\n",
    "\n",
    "## 5.2 Evaluation Results\n",
    "- モデルバリアントの比較分析\n",
    "- チェックポイントごとの性能評価\n",
    "- 最適モデルの選定理由\n",
    "\n",
    "## 5.3 Model Demonstration\n",
    "- ベストモデルによる対話例\n",
    "- 特筆すべき成功事例と課題\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cac082",
   "metadata": {},
   "source": [
    "# 6. Future Directions and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb04b7",
   "metadata": {},
   "source": [
    "\n",
    "## 6.1 Areas for Improvement\n",
    "- 技術的な改善可能点\n",
    "- さらなる研究の方向性\n",
    "- スケールアップの可能性\n",
    "\n",
    "## 6.2 Concluding Thoughts\n",
    "- プロジェクトの成果と意義\n",
    "- AIによる哲学的対話の可能性と限界\n",
    "- 今後の展望\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6483776,
     "sourceId": 10471543,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6483866,
     "sourceId": 10471671,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6483976,
     "sourceId": 10471850,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6483979,
     "sourceId": 10471853,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6483982,
     "sourceId": 10471858,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 121954,
     "modelInstanceId": 98328,
     "sourceId": 116995,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 217387,
     "modelInstanceId": 195488,
     "sourceId": 229255,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 58.713338,
   "end_time": "2025-01-14T23:35:36.525457",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-14T23:34:37.812119",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1ad61aa2ce134f4f8d305ce6bcbb489a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ff174e8e75f477a84e5a32f93538163": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "21a31e34e4314a31a9ddf6397cc87454": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_fba0dc85a5e848b292f98c4ee4c75b1f",
       "msg_id": "",
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": "👋 Welcome! Please enter your Hugging Face token and click 'Initialize AI Assistant' to begin.\n"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "234e5717434745b68b47d4a1b968f8a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100px"
      }
     },
     "24f8498024674fc8992cef6a2c95ad51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "initial",
       "font_size": null,
       "text_color": null
      }
     },
     "3a4e77bb05e94c9390cd0f425bcc6762": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f4e09b73bbe49bf8b221740072d340c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "57ad3cfa3a524f26b21fe4693bfa6d5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ButtonView",
       "button_style": "success",
       "description": "Send",
       "disabled": true,
       "icon": "",
       "layout": "IPY_MODEL_234e5717434745b68b47d4a1b968f8a2",
       "style": "IPY_MODEL_1ff174e8e75f477a84e5a32f93538163",
       "tabbable": null,
       "tooltip": null
      }
     },
     "68e56a4e74c1478189d98285a5da8dda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ButtonView",
       "button_style": "primary",
       "description": "Initialize AI",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_8600104651934e86a9e8e1db3a2ed602",
       "style": "IPY_MODEL_3f4e09b73bbe49bf8b221740072d340c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8600104651934e86a9e8e1db3a2ed602": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": "10px 0",
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "200px"
      }
     },
     "a76aee71a5ff43d796d04d1e7ed31464": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d67bd50805c54680832443b249d00d54",
        "IPY_MODEL_21a31e34e4314a31a9ddf6397cc87454",
        "IPY_MODEL_f9afc36825594b38b19a4839ce895773"
       ],
       "layout": "IPY_MODEL_ae1a4156380944dd8f56ba2848186125",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a7e420b7c04b473fb89cd9e131323772": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "500px"
      }
     },
     "ae1a4156380944dd8f56ba2848186125": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba2e6d0727bb4170a871b6c32332fc3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "500px"
      }
     },
     "c03f7aa62a254d03b5bd8a7d18f19dab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cdcbac4ce6a04cf19cd785d59742a4c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PasswordModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "PasswordModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "PasswordView",
       "continuous_update": true,
       "description": "HF Token:",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_ba2e6d0727bb4170a871b6c32332fc3a",
       "placeholder": "Enter your Hugging Face token",
       "style": "IPY_MODEL_24f8498024674fc8992cef6a2c95ad51",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "d67bd50805c54680832443b249d00d54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cdcbac4ce6a04cf19cd785d59742a4c4",
        "IPY_MODEL_68e56a4e74c1478189d98285a5da8dda"
       ],
       "layout": "IPY_MODEL_3a4e77bb05e94c9390cd0f425bcc6762",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e92f44400a054028bdfebc4a1dd6f09a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "TextView",
       "continuous_update": true,
       "description": "",
       "description_allow_html": false,
       "disabled": true,
       "layout": "IPY_MODEL_a7e420b7c04b473fb89cd9e131323772",
       "placeholder": "Type your message here...",
       "style": "IPY_MODEL_c03f7aa62a254d03b5bd8a7d18f19dab",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "f9afc36825594b38b19a4839ce895773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e92f44400a054028bdfebc4a1dd6f09a",
        "IPY_MODEL_57ad3cfa3a524f26b21fe4693bfa6d5f"
       ],
       "layout": "IPY_MODEL_1ad61aa2ce134f4f8d305ce6bcbb489a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fba0dc85a5e848b292f98c4ee4c75b1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": "1px solid #ddd",
       "border_left": "1px solid #ddd",
       "border_right": "1px solid #ddd",
       "border_top": "1px solid #ddd",
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": "10px 0",
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": "10px",
       "right": null,
       "top": null,
       "visibility": null,
       "width": "600px"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
