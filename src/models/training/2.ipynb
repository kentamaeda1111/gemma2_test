{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.データ準備と前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "このコードの「データ準備と前処理」部分について、ソクラテス式チャットボットの文脈で説明していきます。\n",
    "\n",
    "### 1. データの検証（validate_message_format関数）\n",
    "```python\n",
    "def validate_message_format(message):\n",
    "```\n",
    "この関数は、会話データが正しい形式になっているかをチェックします。\n",
    "\n",
    "例えば以下のような会話データが正しいフォーマットとして扱われます：\n",
    "```json\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"AIについてどう思いますか？\"\n",
    "}\n",
    "{\n",
    "    \"role\": \"model\",\n",
    "    \"content\": \"AIについて、まず何が知りたいのでしょうか？私たちで一緒に考えていきましょう。\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 2. データセットの準備（prepare_dataset関数）\n",
    "```python\n",
    "def prepare_dataset():\n",
    "```\n",
    "この関数は主に3つのことを行います：\n",
    "\n",
    "1. **会話データの読み込みと検証**:\n",
    "   - JSONファイルから会話データを読み込みます\n",
    "   - ユーザーとモデルの会話が交互になっているか確認します\n",
    "\n",
    "2. **会話の整形**:\n",
    "   - Gemmaモデル用の特別な形式に会話を変換します\n",
    "   - 例：\n",
    "     ```\n",
    "     ユーザー: AIの倫理について考えてみましょう\n",
    "     モデル: その問題について、まず何が気になっているのでしょうか？\n",
    "     ```\n",
    "\n",
    "3. **長さのチェック**:\n",
    "   - 会話が長すぎないかチェックします（MAX_SEQUENCE_LENGTH以内）\n",
    "\n",
    "### 3. トークン化（tokenize_function）\n",
    "```python\n",
    "def tokenize_function(examples):\n",
    "```\n",
    "会話テキストを機械学習モデルが理解できる数値（トークン）に変換します。\n",
    "\n",
    "例：\n",
    "```\n",
    "\"なぜでしょうか？\" → [1234, 5678, 9012]\n",
    "```\n",
    "\n",
    "### 4. 前処理（preprocess_function）\n",
    "```python\n",
    "def preprocess_function(examples):\n",
    "```\n",
    "ソクラテス式の特徴的な表現に注目するよう設定します：\n",
    "\n",
    "1. **文末パターンの強調**:\n",
    "   - \"だろうか\"、\"ではないか\"などの問いかけ\n",
    "   - \"なるほど\"、\"興味深い\"などの応答\n",
    "\n",
    "2. **接続詞の強調**:\n",
    "   - \"しかし\"、\"だから\"などの論理展開\n",
    "\n",
    "3. **句読点の強調**:\n",
    "   - 「、」「。」「！」「？」の位置を記録\n",
    "\n",
    "これにより、モデルがソクラテス式の対話の特徴（問いかけ、論理的な展開、適切な間の取り方など）により注意を払うようになります。\n",
    "\n",
    "このような前処理によって、モデルは：\n",
    "- 適切なタイミングで質問を投げかけ\n",
    "- 論理的な会話の流れを作り\n",
    "- ソクラテス式の対話らしい応答を生成\n",
    "できるように学習データが整えられます。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_message_format(message):\n",
    "    \"\"\"Validate message format\"\"\"\n",
    "    if not isinstance(message, dict):\n",
    "        return False\n",
    "    if 'role' not in message or 'content' not in message:\n",
    "        return False\n",
    "    if message['role'] not in ['user', 'model']:\n",
    "        return False\n",
    "    if not isinstance(message['content'], str):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "この関数は対話データの各メッセージが正しい形式かチェックします：\n",
    "- 辞書型であること\n",
    "- 'role'と'content'のキーがあること\n",
    "- roleが'user'か'model'であること\n",
    "- contentが文字列であること\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #ffe6e6; padding: 10px; border-left: 5px solid #8b0000; margin: 10px; width: 95%;\">\n",
    "    <summary style=\"color: #8b0000; font-size: 1.17em; font-weight: bold;\">補足</summary>\n",
    "    <div style=\"color: #8b0000;\">\n",
    "\n",
    "\n",
    "対話がuserからはじまるかどうかはチェックしてない？\n",
    "\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    conversations = []\n",
    "    \n",
    "    try:\n",
    "        with open(DIALOGUE_JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "            dialogue_data = json.load(f)\n",
    "            \n",
    "        for dialogue in dialogue_data:\n",
    "            messages = dialogue.get('messages', [])\n",
    "            \n",
    "            # Validate message format\n",
    "            if not all(validate_message_format(msg) for msg in messages):\n",
    "                logging.warning(f\"Skipped dialogue due to invalid message format\")\n",
    "                continue\n",
    "                \n",
    "            # Build conversation checking user->model sequence\n",
    "            current_conversation = []\n",
    "            valid_sequence = True\n",
    "            \n",
    "            for i in range(0, len(messages)-1, 2):\n",
    "                if (i+1 < len(messages) and \n",
    "                    messages[i]['role'] == 'user' and \n",
    "                    messages[i+1]['role'] == 'model'):\n",
    "                    current_conversation.extend([messages[i], messages[i+1]])\n",
    "                else:\n",
    "                    valid_sequence = False\n",
    "                    break\n",
    "            \n",
    "            # 会話が有効で内容があれば処理\n",
    "            if valid_sequence and current_conversation:\n",
    "                # Gemmaモデル用のチャットテンプレートを適用\n",
    "                formatted_text = tokenizer.apply_chat_template(\n",
    "                    current_conversation,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "                \n",
    "                # トークン数をチェック\n",
    "                tokens = tokenizer.encode(formatted_text)\n",
    "                if len(tokens) <= MAX_SEQUENCE_LENGTH:\n",
    "                    # 長さが適切なら追加\n",
    "                    conversations.append({\"text\": formatted_text})\n",
    "                else:\n",
    "                    # 長すぎる場合はスキップ\n",
    "                    logging.warning(f\"Skipped conversation due to length: {len(tokens)} tokens\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # エラーが発生した場合はログに記録して再発生\n",
    "        logging.error(f\"Error processing dialogue file: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    # 有効な会話がなければエラー\n",
    "    if not conversations:\n",
    "        raise ValueError(\"No valid conversations found in the dialogue file\")\n",
    "\n",
    "    # 処理した会話数をログに記録    \n",
    "    logging.info(f\"Processed {len(conversations)} valid conversations\")\n",
    "\n",
    "    # 会話リストからデータセットを作成して返す\n",
    "    return Dataset.from_list(conversations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "**この関数が行っていること**:\n",
    "1. JSONファイルから対話データを読み込む\n",
    "2. 各対話について：\n",
    "   - メッセージ形式を検証\n",
    "   - ユーザー→モデルの順序を確認\n",
    "   - Gemmaモデル用に形式を整える\n",
    "   - トークン数をチェック\n",
    "3. 有効な会話のみを保持\n",
    "4. データセットとして返す\n",
    "\n",
    "**重要なチェック項目**:\n",
    "- メッセージの形式\n",
    "- 会話の順序（ユーザー→モデル）\n",
    "- トークンの長さ制限\n",
    "- エラー処理とログ記録\n",
    "\n",
    "このコードは、生の対話データを機械学習モデルで使用できる形式に変換する重要な前処理ステップを担っています。\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dataset preparation\n",
    "dataset = prepare_dataset()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "        \n",
    "**データセットの準備**:\n",
    "\n",
    "- 先ほど説明した`prepare_dataset()`関数を使用してデータセットを作成\n",
    "- 対話データをモデル学習用のフォーマットに変換\n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset[0])  # Display first element\n",
    "print(\"\\nDataset features:\")\n",
    "print(dataset.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "**データセット構造の確認**:\n",
    "\n",
    "- データセットの最初の要素を表示して構造を確認\n",
    "- 例えば以下のような出力が期待される：\n",
    "```\n",
    "Dataset structure:\n",
    "{'text': 'User: こんにちは\\nAssistant: はい、こんにちは。...'}\n",
    "\n",
    "Dataset features:\n",
    "{'text': Value(dtype='string', id=None)}\n",
    "```\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optimize dataset batch processing\n",
    "dataset = dataset.select(range(len(dataset))).shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "**データセットの最適化**:\n",
    "```python\n",
    "# データセットのバッチ処理の最適化\n",
    "dataset = dataset.select(range(len(dataset))).shuffle(seed=42)\n",
    "```\n",
    "- `select(range(len(dataset)))`: データセット全体を選択\n",
    "- `shuffle(seed=42)`: データをランダムに並び替え\n",
    "  - `seed=42`: 再現性のために固定の乱数シードを使用\n",
    "  - 学習時のデータの偏りを防ぐため\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f3ff; padding: 10px; border-left: 5px solid #2196F3; margin: 10px; width: 95%;\">\n",
    "<summary style=\"color: #2196F3; font-size: 1.17em; font-weight: bold;\">Q. 質問内容</summary>\n",
    "<p style=\"color: #2196F3;\">\n",
    "\n",
    "jsonの中に例えば\n",
    "\n",
    "user1発話目\n",
    "model１発話目\n",
    "user2発話目\n",
    "model2発話目\n",
    "\n",
    "の計４発話がひとくくりになって、１つの対話になっていて、その対話が１００個あった場合、シャッフルされるのはその１００個の対話の配置ですか？それとも\n",
    "”user1発話目とmodel１発話目の１ペア”を１つの単位として切り出して、１ペアを最小単位としてシャッフルされるんですか\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f5f5f5; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #4CAF50; font-size: 1.17em; font-weight: bold;\">A. 解答</summary>\n",
    "        <div style=\"color: #4CAF50;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "コードを確認すると、シャッフルされるのは「対話単位」です。つまり、100個の対話の配置がシャッフルされます。\n",
    "\n",
    "これは以下のコードの流れから分かります：\n",
    "\n",
    "1. **対話の処理（`prepare_dataset`関数内）**:\n",
    "```python\n",
    "for dialogue in dialogue_data:\n",
    "    messages = dialogue.get('messages', [])\n",
    "    \n",
    "    # ... 検証処理 ...\n",
    "    \n",
    "    # user->model のペアを保持したまま会話を構築\n",
    "    current_conversation = []\n",
    "    for i in range(0, len(messages)-1, 2):\n",
    "        if (i+1 < len(messages) and \n",
    "            messages[i]['role'] == 'user' and \n",
    "            messages[i+1]['role'] == 'model'):\n",
    "            current_conversation.extend([messages[i], messages[i+1]])\n",
    "    \n",
    "    # 会話全体を1つのユニットとして保存\n",
    "    if valid_sequence and current_conversation:\n",
    "        formatted_text = tokenizer.apply_chat_template(\n",
    "            current_conversation,  # 会話全体を1つのテキストに\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        conversations.append({\"text\": formatted_text})\n",
    "```\n",
    "\n",
    "2. **シャッフル処理**:\n",
    "```python\n",
    "dataset = dataset.select(range(len(dataset))).shuffle(seed=42)\n",
    "```\n",
    "\n",
    "つまり：\n",
    "```\n",
    "[対話1]\n",
    "- user1発話目\n",
    "- model1発話目\n",
    "- user2発話目\n",
    "- model2発話目\n",
    "\n",
    "[対話2]\n",
    "- user1発話目\n",
    "- model1発話目\n",
    "- user2発話目\n",
    "- model2発話目\n",
    "\n",
    "... （100個の対話）\n",
    "```\n",
    "\n",
    "これらの対話単位でシャッフルされます。対話内の発話順序（user→model→user→model）は維持されます。\n",
    "\n",
    "シャッフル後のイメージ：\n",
    "```\n",
    "[対話54]\n",
    "- user1発話目\n",
    "- model1発話目\n",
    "- user2発話目\n",
    "- model2発話目\n",
    "\n",
    "[対話12]\n",
    "- user1発話目\n",
    "- model1発話目\n",
    "- user2発話目\n",
    "- model2発話目\n",
    "\n",
    "[対話87]\n",
    "...\n",
    "```\n",
    "\n",
    "個々の発話ペアをバラバラにシャッフルしないのは、文脈の一貫性を保つためです。対話の流れを保持したまま、異なる対話のトピックが適度に混ざるようにしています。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Log dataset size\n",
    "logging.info(f\"Total dataset size: {len(dataset)}\")\n",
    "log_memory_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    " **サイズとメモリ使用量の記録**:\n",
    "```python\n",
    "# データセットサイズのログ記録\n",
    "logging.info(f\"Total dataset size: {len(dataset)}\")\n",
    "log_memory_usage()\n",
    "```\n",
    "- データセットの総サイズをログに記録\n",
    "- メモリ使用状況を確認（CPU・GPUのメモリ使用量）\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_function(examples):\n",
    "    result = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=TOKENIZE_MAX_LENGTH,      # 256 から TOKENIZE_MAX_LENGTH に変更\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "この`tokenize_function`は、テキストをモデルが理解できる数値形式（トークン）に変換する関数です。詳しく説明します：\n",
    "\n",
    "```python\n",
    "def tokenize_function(examples):\n",
    "    # examplesは複数の対話テキストを含む辞書\n",
    "    # examples['text']の例：\n",
    "    # [\"User: こんにちは\\nAssistant: はい、こんにちは。\", \n",
    "    #  \"User: 天気は？\\nAssistant: 今日は晴れです。\", ...]\n",
    "    \n",
    "    result = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,                    # 長すぎるテキストを切り詰める\n",
    "        max_length=TOKENIZE_MAX_LENGTH,     # 最大長（例：512）\n",
    "        padding='max_length',               # 短いテキストを最大長まで埋める\n",
    "        add_special_tokens=True,            # [BOS], [EOS]などの特殊トークンを追加\n",
    "        return_tensors=None,                # 通常のPythonリストとして返す\n",
    "    )\n",
    "    return result\n",
    "```\n",
    "\n",
    "**具体例**:\n",
    "```python\n",
    "# 入力テキスト\n",
    "text = \"User: こんにちは\\nAssistant: はい、こんにちは。\"\n",
    "\n",
    "# トークン化の結果（イメージ）\n",
    "result = {\n",
    "    'input_ids': [1, 245, 567, 89, ..., 0, 0],  # テキストを数値に変換\n",
    "    'attention_mask': [1, 1, 1, 1, ..., 0, 0]   # 実際のトークンは1、パディングは0\n",
    "}\n",
    "```\n",
    "\n",
    "**各パラメータの説明**:\n",
    "\n",
    "1. **truncation=True**:\n",
    "   ```python\n",
    "   # 長すぎるテキスト\n",
    "   長いテキスト = \"とても長い文章...\" # 1000トークン\n",
    "   \n",
    "   # 切り詰め後\n",
    "   結果 = \"とても長い...\" # TOKENIZE_MAX_LENGTH（例：512）トークンまで\n",
    "   ```\n",
    "\n",
    "2. **padding='max_length'**:\n",
    "   ```python\n",
    "   # 短いテキスト\n",
    "   短いテキスト = \"こんにちは\"  # 5トークン\n",
    "   \n",
    "   # パディング後\n",
    "   結果 = \"こんにちは[PAD][PAD]...\"  # TOKENIZE_MAX_LENGTHまで[PAD]で埋める\n",
    "   ```\n",
    "\n",
    "3. **add_special_tokens=True**:\n",
    "   ```python\n",
    "   # 特殊トークンの追加\n",
    "   元テキスト = \"こんにちは\"\n",
    "   結果 = \"[BOS]こんにちは[EOS]\"  # 文の始まりと終わりを示すトークンを追加\n",
    "   ```\n",
    "\n",
    "**使用例**:\n",
    "```python\n",
    "# データセットに適用\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,  # バッチ処理で効率化\n",
    "    num_proc=2,    # 複数プロセスで並列処理\n",
    "    desc=\"Tokenizing datasets\"\n",
    ")\n",
    "```\n",
    "\n",
    "このトークン化は、テキストをモデルが処理できる形式に変換する重要な前処理ステップです。すべての入力テキストを同じ長さに揃え、特殊トークンを適切に配置することで、モデルの学習が効率的に行えるようになります。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Add dataset preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # Pattern definitions\n",
    "    end_patterns = [\n",
    "        \"だろうか\", \"ではないか\", \"のではないか\", \"かね\",\n",
    "        \"なるほど\", \"興味深い\", \"考えてみよう\"\n",
    "    ]\n",
    "    \n",
    "    # Conjunction patterns\n",
    "    conjunctions = [\n",
    "        \"しかし\", \"だから\", \"それでは\", \"すなわち\",\n",
    "        \"たとえば\", \"つまり\", \"ならば\", \"もし\"\n",
    "    ]\n",
    "    \n",
    "    # Get tokenized texts\n",
    "    texts = tokenizer.batch_decode(examples['input_ids'])\n",
    "    new_attention_masks = []\n",
    "    \n",
    "    for text, mask in zip(texts, examples['attention_mask']):\n",
    "        if not isinstance(mask, list):\n",
    "            mask = mask.tolist()\n",
    "        \n",
    "        # Create new attention mask (base value 0.8)\n",
    "        new_mask = [0.8] * len(mask)\n",
    "        \n",
    "        # Split into sentences\n",
    "        sentences = text.split('。')\n",
    "        current_pos = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if not sentence.strip():\n",
    "                continue\n",
    "                \n",
    "            # Detect and emphasize end patterns\n",
    "            for pattern in end_patterns:\n",
    "                if pattern in sentence:\n",
    "                    # Locate pattern position\n",
    "                    pattern_tokens = tokenizer.encode(pattern, add_special_tokens=False)\n",
    "                    pattern_len = len(pattern_tokens)\n",
    "                    \n",
    "                    # Emphasize tokens containing pattern and surrounding tokens\n",
    "                    pattern_start = current_pos + len(tokenizer.encode(sentence, add_special_tokens=False)) - pattern_len\n",
    "                    for i in range(max(0, pattern_start - 2), min(len(mask), pattern_start + pattern_len + 2)):\n",
    "                        new_mask[i] = 1.0  # Maximum attention for pattern parts\n",
    "            \n",
    "            # Detect and emphasize conjunctions\n",
    "            for conj in conjunctions:\n",
    "                if conj in sentence:\n",
    "                    # Locate conjunction position\n",
    "                    conj_tokens = tokenizer.encode(conj, add_special_tokens=False)\n",
    "                    conj_pos = len(tokenizer.encode(sentence.split(conj)[0], add_special_tokens=False))\n",
    "                    \n",
    "                    # Emphasize tokens before and after conjunction (slightly lower)\n",
    "                    for i in range(max(0, current_pos + conj_pos - 1), \n",
    "                                 min(len(mask), current_pos + conj_pos + len(conj_tokens) + 1)):\n",
    "                        new_mask[i] = 0.9\n",
    "            \n",
    "            # Emphasize punctuation marks\n",
    "            for i, char in enumerate(sentence):\n",
    "                if char in '、。！？':\n",
    "                    # Locate punctuation position\n",
    "                    punct_pos = len(tokenizer.encode(sentence[:i], add_special_tokens=False))\n",
    "                    # Emphasize tokens around punctuation\n",
    "                    for j in range(max(0, current_pos + punct_pos - 1),\n",
    "                                 min(len(mask), current_pos + punct_pos + 2)):\n",
    "                        new_mask[j] = 0.95\n",
    "            \n",
    "            # Update position for next sentence\n",
    "            current_pos += len(tokenizer.encode(sentence + '。', add_special_tokens=False))\n",
    "        \n",
    "        # Set special token masks to 1.0\n",
    "        if tokenizer.bos_token_id is not None:\n",
    "            new_mask[0] = 1.0  # BOS token\n",
    "        if tokenizer.eos_token_id is not None:\n",
    "            new_mask[-1] = 1.0  # EOS token\n",
    "            \n",
    "        new_attention_masks.append(new_mask)\n",
    "\n",
    "    examples['attention_mask'] = new_attention_masks\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "このコードは、ソクラテス式問答のテキストに対して、重要な部分により注意を向けるように設定する前処理関数です。具体例を交えて説明します：\n",
    "\n",
    "1. **パターンの定義**:\n",
    "```python\n",
    "# 文末パターン\n",
    "end_patterns = [\n",
    "    \"だろうか\", \"ではないか\", \"のではないか\", \"かね\",\n",
    "    \"なるほど\", \"興味深い\", \"考えてみよう\"\n",
    "]\n",
    "# 例：「真理とは何だろうか」「それは興味深い考えではないか」\n",
    "\n",
    "# 接続パターン\n",
    "conjunctions = [\n",
    "    \"しかし\", \"だから\", \"それでは\", \"すなわち\",\n",
    "    \"たとえば\", \"つまり\", \"ならば\", \"もし\"\n",
    "]\n",
    "# 例：「しかし、それは本当の知恵といえるでしょうか」\n",
    "```\n",
    "\n",
    "2. **具体的な処理例**:\n",
    "```python\n",
    "# 入力テキストの例\n",
    "text = \"\"\"\n",
    "User: 知識と知恵の違いについて考えてみましょう。\n",
    "Assistant: なるほど、興味深いテーマですね。まず、知識とは何だろうか。たとえば、本から得られる情報は知識といえます。しかし、その知識を適切に活用できることが、すなわち知恵ではないでしょうか。\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "3. **注意度の設定**:\n",
    "```python\n",
    "# 基本の注意度: 0.8\n",
    "\"知識と知恵の違いについて\" -> [0.8, 0.8, 0.8, ...]\n",
    "\n",
    "# 文末パターンの強調（注意度: 1.0）\n",
    "\"何だろうか\" -> [1.0, 1.0, 1.0]\n",
    "\"ではないでしょうか\" -> [1.0, 1.0, 1.0]\n",
    "\n",
    "# 接続詞の強調（注意度: 0.9）\n",
    "\"しかし\" -> [0.9, 0.9]\n",
    "\"すなわち\" -> [0.9, 0.9, 0.9]\n",
    "\n",
    "# 句読点の強調（注意度: 0.95）\n",
    "\"、\" -> [0.95]\n",
    "\"。\" -> [0.95]\n",
    "```\n",
    "\n",
    "4. **処理の流れ**:\n",
    "```python\n",
    "# 例文：「知識とは何だろうか。しかし、それは本当の答えではないかもしれません。」\n",
    "\n",
    "# 1. 文分割\n",
    "sentences = [\n",
    "    \"知識とは何だろうか\",\n",
    "    \"しかし、それは本当の答えではないかもしれません\"\n",
    "]\n",
    "\n",
    "# 2. 各文でパターンを検出\n",
    "- \"だろうか\" を検出 → 注意度1.0\n",
    "- \"しかし\" を検出 → 注意度0.9\n",
    "- \"、\" を検出 → 注意度0.95\n",
    "- \"。\" を検出 → 注意度0.95\n",
    "\n",
    "# 3. 注意マスクの生成\n",
    "[0.8, 0.8, 0.8, 1.0, 1.0, 0.95, 0.9, 0.8, 0.8, 0.95, ...]\n",
    "```\n",
    "\n",
    "5. **目的**:\n",
    "- ソクラテス式問答の重要な要素に注目\n",
    "  - 問いかけの部分（「だろうか」など）\n",
    "  - 論理の展開（接続詞）\n",
    "  - 文の区切り（句読点）\n",
    "- これにより、モデルが:\n",
    "  - 適切な問いかけ方を学習\n",
    "  - 論理的な文章の構造を理解\n",
    "  - 文の区切りを適切に認識\n",
    "\n",
    "このように、ソクラテス式問答の特徴的な表現や構造に対して、モデルがより注意を払うように設定しています。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f3ff; padding: 10px; border-left: 5px solid #2196F3; margin: 10px; width: 95%;\">\n",
    "<summary style=\"color: #2196F3; font-size: 1.17em; font-weight: bold;\">Q. 質問内容</summary>\n",
    "<p style=\"color: #2196F3;\">これは目的関数に関わることですか？それともあくまで評価時の項目ですか</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f5f5f5; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #4CAF50; font-size: 1.17em; font-weight: bold;\">A. 解答</summary>\n",
    "        <div style=\"color: #4CAF50;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "このコードは**目的関数（損失関数）に直接影響を与えます**。具体的には、Attention Maskを通じてモデルの学習過程自体に影響を与えます。\n",
    "\n",
    "以下で詳しく説明します：\n",
    "\n",
    "1. **Attention Maskの役割**:\n",
    "```python\n",
    "# 通常のAttention Mask（0か1のみ）\n",
    "normal_mask = [1, 1, 1, 1, 0, 0]  # 1: 有効なトークン、0: パディング\n",
    "\n",
    "# このコードによるAttention Mask（0.8～1.0の値）\n",
    "custom_mask = [0.8, 1.0, 0.9, 0.95, 0, 0]\n",
    "# 0.8: 基本的な注意度\n",
    "# 1.0: 重要な文末表現（「だろうか」など）\n",
    "# 0.9: 接続詞\n",
    "# 0.95: 句読点\n",
    "```\n",
    "\n",
    "2. **学習への影響**:\n",
    "```python\n",
    "# 例：ソクラテス式の問答\n",
    "text = \"知識とは何だろうか。しかし、それは表面的な理解かもしれない。\"\n",
    "\n",
    "# 注意度の重み付け\n",
    "\"知識とは\"        -> 0.8  # 基本の注意度\n",
    "\"何だろうか\"      -> 1.0  # 問いかけ表現として重要\n",
    "\"しかし\"          -> 0.9  # 論理展開の接続詞\n",
    "\"、\"              -> 0.95 # 文の区切り\n",
    "\"かもしれない\"    -> 1.0  # 思考を促す表現\n",
    "```\n",
    "\n",
    "3. **目的関数への影響**:\n",
    "- モデルの学習時に、これらの重み付けが損失関数の計算に影響\n",
    "- より重要な部分（注意度が高い部分）の誤差がより大きく反映される\n",
    "- 結果として、モデルは:\n",
    "  - 問いかけ表現の適切な使用\n",
    "  - 論理的な文章の構造\n",
    "  - 適切な句読点の使用\n",
    "  を重点的に学習する\n",
    "\n",
    "4. **評価時との違い**:\n",
    "```python\n",
    "# 学習時：\n",
    "- Attention Maskの重みが損失関数に直接影響\n",
    "- モデルのパラメータ更新に影響\n",
    "\n",
    "# 評価時：\n",
    "- compute_metrics()関数で別途評価\n",
    "- モデルの出力を評価するだけで、学習には影響しない\n",
    "```\n",
    "\n",
    "したがって、このコードは：\n",
    "- 単なる評価指標ではなく\n",
    "- 学習プロセス自体に組み込まれた\n",
    "- モデルの振る舞いを直接制御する仕組み\n",
    "\n",
    "として機能しています。これにより、ソクラテス式問答の特徴をモデルにより効果的に学習させることができます。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optimize dataset processing\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    num_proc=2,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing datasets\",\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "このコードは、データセットのトークン化処理を最適化して実行するものです。具体的に説明します：\n",
    "\n",
    "```python\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,     # 先ほど定義したトークン化関数\n",
    "    batched=True,         # バッチ処理を有効化\n",
    "    batch_size=16,        # 一度に処理するサンプル数\n",
    "    num_proc=2,           # 使用するプロセス数\n",
    "    load_from_cache_file=True,  # キャッシュの使用\n",
    "    desc=\"Tokenizing datasets\",  # 進捗表示の説明\n",
    "    remove_columns=dataset.column_names,  # 元のカラムを削除\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "**具体例で説明**:\n",
    "\n",
    "1. **バッチ処理**:\n",
    "```python\n",
    "# バッチ処理なし（非効率）\n",
    "for text in dataset:\n",
    "    tokenize_function(text)  # 1つずつ処理\n",
    "\n",
    "# バッチ処理あり（効率的）\n",
    "batch = [\n",
    "    \"User: 知識とは何でしょうか\\nAssistant: 考えてみましょう...\",\n",
    "    \"User: 真理について\\nAssistant: 興味深い質問ですね...\",\n",
    "    ...  # 16個のテキストを一度に処理\n",
    "]\n",
    "tokenize_function(batch)\n",
    "```\n",
    "\n",
    "\n",
    "2. **並列処理**:\n",
    "```python\n",
    "num_proc=2  # 2つのプロセスで並列処理\n",
    "\n",
    "プロセス1: [テキスト1, テキスト2, テキスト3, ...]\n",
    "プロセス2: [テキスト16, テキスト17, テキスト18, ...]\n",
    "```\n",
    "\n",
    "\n",
    "3. **キャッシュの使用**:\n",
    "```python\n",
    "load_from_cache_file=True\n",
    "\n",
    "# 初回実行時\n",
    "1. トークン化を実行\n",
    "2. 結果をキャッシュに保存\n",
    "\n",
    "# 2回目以降の実行時\n",
    "1. キャッシュがあれば、それを読み込む\n",
    "2. トークン化処理をスキップ\n",
    "```\n",
    "\n",
    "\n",
    "4. **カラムの削除**:\n",
    "```python\n",
    "# 処理前のデータセット\n",
    "{\n",
    "    'text': ['対話テキスト1', '対話テキスト2', ...],\n",
    "    'other_column': [...]\n",
    "}\n",
    "\n",
    "# 処理後のデータセット（remove_columns効果）\n",
    "{\n",
    "    'input_ids': [[101, 2345, ...], [101, 5678, ...], ...],\n",
    "    'attention_mask': [[1, 1, ...], [1, 1, ...], ...]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "**最適化の利点**:\n",
    "\n",
    "1. **処理速度の向上**:\n",
    "   - バッチ処理による効率化\n",
    "   - 複数プロセスによる並列処理\n",
    "   - キャッシュによる再計算の回避\n",
    "\n",
    "2. **メモリ効率**:\n",
    "   - バッチ単位での処理で、メモリ使用を制御\n",
    "   - 不要なカラムの削除\n",
    "\n",
    "3. **進捗の可視化**:\n",
    "   - `desc`パラメータによる処理状況の表示\n",
    "   - 長時間の処理の進行状況が分かる\n",
    "\n",
    "このように、大量の対話データを効率的にトークン化処理するための最適化が施されています。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Add dataset validation\n",
    "def validate_dataset(dataset):\n",
    "    # Check first element\n",
    "    first_item = dataset[0]\n",
    "    print(\"Validated first item structure:\")\n",
    "    print(f\"Keys: {first_item.keys()}\")\n",
    "    print(f\"input_ids type: {type(first_item['input_ids'])}\")\n",
    "    print(f\"input_ids length: {len(first_item['input_ids'])}\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "このコードはデータセットの構造を検証する関数です。具体的な例を使って説明します：\n",
    "\n",
    "```python\n",
    "def validate_dataset(dataset):\n",
    "    # 最初の要素を取得して検証\n",
    "    first_item = dataset[0]\n",
    "    \n",
    "    # 構造の確認と出力\n",
    "    print(\"Validated first item structure:\")\n",
    "    print(f\"Keys: {first_item.keys()}\")  # データの持つキーを表示\n",
    "    print(f\"input_ids type: {type(first_item['input_ids'])}\")  # トークンIDの型を確認\n",
    "    print(f\"input_ids length: {len(first_item['input_ids'])}\")  # トークン列の長さを確認\n",
    "    return dataset\n",
    "```\n",
    "\n",
    "\n",
    "**想定される出力例**:\n",
    "```python\n",
    "Validated first item structure:\n",
    "Keys: dict_keys(['input_ids', 'attention_mask'])\n",
    "input_ids type: <class 'list'>\n",
    "input_ids length: 512\n",
    "```\n",
    "\n",
    "\n",
    "**具体的な検証内容**:\n",
    "\n",
    "1. **キーの確認**:\n",
    "```python\n",
    "# 期待される構造\n",
    "first_item = {\n",
    "    'input_ids': [...],      # トークンのID列\n",
    "    'attention_mask': [...]  # 注意マスク\n",
    "}\n",
    "\n",
    "# キーの出力\n",
    "print(f\"Keys: {first_item.keys()}\")\n",
    "# 期待される出力: Keys: dict_keys(['input_ids', 'attention_mask'])\n",
    "```\n",
    "\n",
    "\n",
    "2. **データ型の確認**:\n",
    "```python\n",
    "# input_idsの型チェック\n",
    "print(f\"input_ids type: {type(first_item['input_ids'])}\")\n",
    "# 期待される出力: input_ids type: <class 'list'>\n",
    "\n",
    "# 実際のデータ例（ソクラテス式問答の場合）\n",
    "input_ids = [\n",
    "    101,  # [BOS]トークン\n",
    "    2345, # \"User:\"に相当するトークン\n",
    "    6789, # \"知識とは何でしょうか\"のトークン\n",
    "    102,  # [EOS]トークン\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "3. **長さの確認**:\n",
    "```python\n",
    "# トークン列の長さチェック\n",
    "print(f\"input_ids length: {len(first_item['input_ids'])}\")\n",
    "# 期待される出力: input_ids length: 512\n",
    "\n",
    "# 長さが512である理由：\n",
    "# - TOKENIZE_MAX_LENGTH = 512 に設定されている\n",
    "# - 短い文章はパディング、長い文章は切り詰めで512に統一\n",
    "```\n",
    "\n",
    "\n",
    "**この検証が重要な理由**:\n",
    "\n",
    "1. **データ形式の確認**:\n",
    "   - モデルが期待する入力形式になっているか\n",
    "   - 必要なキー（input_ids, attention_mask）が存在するか\n",
    "\n",
    "2. **トークン化の確認**:\n",
    "   - トークン化が正しく行われているか\n",
    "   - 設定した最大長（512）が守られているか\n",
    "\n",
    "3. **早期エラー検出**:\n",
    "   - トレーニング開始前に問題を発見できる\n",
    "   - データ形式の不整合を防ぐ\n",
    "\n",
    "このバリデーション関数は、トレーニングの前にデータセットが正しい形式になっていることを確認する重要なステップです。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = validate_dataset(tokenized_dataset)\n",
    "\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Applying attention masking\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "このコードは、トークン化されたデータセットの検証と前処理を順番に行っています：\n",
    "\n",
    "1. **データセット検証**:\n",
    "```python\n",
    "# トークン化されたデータセットを検証\n",
    "tokenized_dataset = validate_dataset(tokenized_dataset)\n",
    "\n",
    "# 想定される出力例\n",
    "Validated first item structure:\n",
    "Keys: dict_keys(['input_ids', 'attention_mask'])\n",
    "input_ids type: <class 'list'>\n",
    "input_ids length: 512\n",
    "```\n",
    "\n",
    "2. **注意マスクの適用**:\n",
    "```python\n",
    "# 検証済みデータセットに前処理（注意マスク）を適用\n",
    "tokenized_dataset = tokenized_dataset.map(\n",
    "    preprocess_function,  # 先ほど説明した前処理関数\n",
    "    batched=True,        # バッチ処理を有効化\n",
    "    desc=\"Applying attention masking\"  # 進捗表示の説明\n",
    ")\n",
    "```\n",
    "\n",
    "**処理の流れ**:\n",
    "```python\n",
    "# 1. 元のデータ（data/dialogue/processed/kaggle_model.json）\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"知識とは何でしょうか\"},\n",
    "        {\"role\": \"model\", \"content\": \"興味深い質問ですね。考えてみましょう...\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 2. トークン化後のデータ\n",
    "{\n",
    "    'input_ids': [101, 2345, 6789, ...],  # トークンID列\n",
    "    'attention_mask': [1, 1, 1, ...]      # 基本的な注意マスク\n",
    "}\n",
    "\n",
    "# 3. 検証（validate_dataset）\n",
    "- キーの存在確認\n",
    "- データ型の確認\n",
    "- 長さの確認\n",
    "\n",
    "# 4. 注意マスクの適用（preprocess_function）\n",
    "{\n",
    "    'input_ids': [101, 2345, 6789, ...],\n",
    "    'attention_mask': [0.8, 1.0, 0.9, ...]  # カスタマイズされた注意マスク\n",
    "}\n",
    "```\n",
    "\n",
    "**この順序が重要な理由**:\n",
    "\n",
    "1. **安全性**:\n",
    "   - 前処理を適用する前にデータ構造を検証\n",
    "   - 問題があれば早期に発見可能\n",
    "\n",
    "2. **デバッグ容易性**:\n",
    "   - 各ステップの出力を確認可能\n",
    "   - エラーの原因特定が容易\n",
    "\n",
    "3. **処理の一貫性**:\n",
    "   - 検証済みのデータに対して前処理を適用\n",
    "   - データの品質を保証\n",
    "\n",
    "このように、データの検証と前処理を順序立てて行うことで、安全で信頼性の高いデータセットの準備が可能になります。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
