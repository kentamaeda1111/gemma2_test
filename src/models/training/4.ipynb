{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "このTraining Frameworkの部分について、プロジェクトの文脈に沿って説明させていただきます。\n",
    "\n",
    "このコードは大きく5つの部分に分かれており、ソクラテス風チャットボットの学習過程を監視・評価するためのフレームワークを構築しています：\n",
    "\n",
    "### 1. システムリソースの監視 (4.1)\n",
    "```python\n",
    "def log_memory_usage():\n",
    "    \"\"\"Log memory usage\"\"\"\n",
    "```\n",
    "- コンピュータのメモリ使用状況を監視します\n",
    "- 学習中にメモリが不足しないよう見張る番人のような役割です\n",
    "\n",
    "### 2. 評価指標の計算 (4.2)\n",
    "```python\n",
    "def compute_metrics(eval_preds):\n",
    "```\n",
    "- チャットボットの返答がどれだけ「ソクラテス風」になっているかを数値化します\n",
    "- 例えば：\n",
    "  - 「かね？」「だろうか？」などの問いかけ口調：60%の重み\n",
    "  - 「君は」「君が」などの二人称の使用：25%の重み\n",
    "  - 「では」「について」などの導入表現：15%の重み\n",
    "- これらの要素を組み合わせて0〜1の間でスコアを算出します\n",
    "\n",
    "### 3. 学習過程の記録 (4.3)\n",
    "```python\n",
    "class StyleCallback(TrainerCallback):\n",
    "class TrainingMonitorCallback(TrainerCallback):\n",
    "```\n",
    "- 学習の進捗を監視し、記録します\n",
    "- 例えば：\n",
    "  - ソクラテス風スコアの推移\n",
    "  - 学習の損失値（モデルの改善度合い）\n",
    "  - 学習率の変化\n",
    "- これらをグラフ化して視覚的に確認できるようにします\n",
    "\n",
    "### 4. カスタム学習器 (4.4)\n",
    "```python\n",
    "class CustomTrainer(Trainer):\n",
    "```\n",
    "- 効率的な学習のための特別な設定を行います\n",
    "- メモリの使用を最適化し、評価用のデータセットを適切なサイズに制限します\n",
    "\n",
    "### 5. 学習設定 (4.5)\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "```\n",
    "- 学習の具体的な設定を行います：\n",
    "  - 30エポック（全データを30周学習）\n",
    "  - 20ステップごとに評価\n",
    "  - バッチサイズ4（一度に4つの対話を学習）\n",
    "  - など\n",
    "\n",
    "これは、例えば料理人が新しいレシピを開発する過程に似ています：\n",
    "- 材料（学習データ）を使って料理（モデル）を作り\n",
    "- 味見（評価）をしながら\n",
    "- レシピ（パラメータ）を調整し\n",
    "- その過程を記録して\n",
    "- より良い料理（ソクラテス風の応答）ができるまで繰り返す\n",
    "\n",
    "このフレームワークのおかげで、モデルがどれだけソクラテス風の話し方を身につけているか、常に監視しながら学習を進めることができます。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 System Resource Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4.1 System Resource Monitoring\n",
    "def log_memory_usage():\n",
    "    \"\"\"Log memory usage\"\"\"\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    logging.info(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Memory release function during training\"\"\"\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "System Resource Monitoring（システムリソースの監視）について、より詳しく説明させていただきます。\n",
    "\n",
    "### 概要\n",
    "このコードは、ソクラテス風チャットボットの学習中にコンピュータのメモリ（記憶領域）の使用状況を監視・管理する2つの関数を定義しています。\n",
    "\n",
    "### 1. メモリ使用量の記録 (`log_memory_usage()`)\n",
    "```python\n",
    "def log_memory_usage():\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    logging.info(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "```\n",
    "\n",
    "これは「メモリの使用量を確認して記録する関数」です。\n",
    "\n",
    "例えると、料理人（開発者）が冷蔵庫（メモリ）の中身をチェックするようなものです：\n",
    "- どれくらいの材料（データ）が入っているか\n",
    "- あとどれくらい材料を入れられるか\n",
    "- 冷蔵庫が一杯になりそうな時は警告を出す\n",
    "\n",
    "具体的には：\n",
    "- 学習データ（ソクラテス風の対話データ）\n",
    "- モデル自体（gemma-2b-jp）\n",
    "- 計算途中の結果\n",
    "などが、どれくらいメモリを使用しているかを監視します。\n",
    "\n",
    "### 2. メモリの解放 (`clear_memory()`)\n",
    "```python\n",
    "def clear_memory():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "これは「使い終わったメモリを掃除する関数」です。\n",
    "\n",
    "例えると：\n",
    "- 使い終わった食器（不要になったデータ）を洗って片付ける\n",
    "- 調理台（作業スペース）を綺麗に掃除する\n",
    "- 次の料理（学習）の準備をする\n",
    "\n",
    "具体的には：\n",
    "- 評価が終わった対話データ\n",
    "- 計算済みの中間結果\n",
    "- 一時的な変数\n",
    "などの不要になったデータをメモリから削除します。\n",
    "\n",
    "### なぜこれが必要か？\n",
    "\n",
    "ソクラテス風チャットボットの学習では：\n",
    "1. 大量の対話データを扱う\n",
    "2. モデル自体も大きい\n",
    "3. GPUでの計算も多い\n",
    "\n",
    "そのため、メモリ管理が重要です：\n",
    "- メモリ不足で学習が途中で止まるのを防ぐ\n",
    "- 学習速度を維持する\n",
    "- システムの安定性を確保する\n",
    "\n",
    "例えば、1000組の対話データを学習させる場合：\n",
    "- 各対話の処理後にメモリをチェック\n",
    "- メモリ使用量が高くなったら掃除（解放）\n",
    "- また次の対話の学習を続ける\n",
    "\n",
    "このように、効率的なメモリ管理によって、長時間の学習を安定して行うことができます。\n",
    "\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Metrics Calculation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4.2 Metrics Calculation System\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds  # Get logits and labels from eval_preds\n",
    "    \n",
    "    # Improve decoding process\n",
    "    with torch.no_grad():\n",
    "        logits = torch.tensor(logits).cpu()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Decode entire batch\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        \n",
    "        # Add more detailed log output\n",
    "        logging.info(f\"Sample prediction: {decoded_preds[0][:100]}...\")\n",
    "        \n",
    "        del logits, predictions  # Memory release\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        socratic_patterns = {\n",
    "            'question_endings': ['かね', 'だろうか', 'ではないかね'],\n",
    "            'address_patterns': ['君は', '君が', '君の'],\n",
    "            'inquiry_leads': ['では', 'について']\n",
    "        }\n",
    "\n",
    "        def calculate_socratic_style(text):\n",
    "            sentences = text.split('。')\n",
    "            if not sentences:\n",
    "                return 0.0\n",
    "            \n",
    "            scores = []\n",
    "            for sent in sentences:\n",
    "                if not sent.strip():\n",
    "                    continue\n",
    "                \n",
    "                # Check if sentence ends with a question\n",
    "                ends_with_question = any(sent.endswith(p) for p in socratic_patterns['question_endings'])\n",
    "                # Proper use of second person\n",
    "                uses_proper_address = any(p in sent for p in socratic_patterns['address_patterns'])\n",
    "                # Use of inquiry introduction\n",
    "                uses_inquiry_lead = any(p in sent for p in socratic_patterns['inquiry_leads'])\n",
    "                \n",
    "                # Sentence score (emphasize ending with a question)\n",
    "                sentence_score = (\n",
    "                    (ends_with_question * 0.6) +\n",
    "                    (uses_proper_address * 0.25) +\n",
    "                    (uses_inquiry_lead * 0.15)\n",
    "                )\n",
    "                scores.append(sentence_score)\n",
    "            \n",
    "            return np.mean(scores) if scores else 0.0\n",
    "\n",
    "        style_scores = [calculate_socratic_style(pred) for pred in decoded_preds]\n",
    "        final_score = np.mean(style_scores)\n",
    "        \n",
    "        return {\n",
    "            'socratic_style': final_score,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "この部分は「ソクラテス風の話し方」をどれだけ習得できているかを数値化して評価するシステムです。詳しく説明していきます：\n",
    "\n",
    "### 1. 評価の準備\n",
    "```python\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    with torch.no_grad():\n",
    "        logits = torch.tensor(logits).cpu()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "```\n",
    "- モデルの出力（数値の羅列）を実際の文章に変換する準備をします\n",
    "- `with torch.no_grad():`は不要なメモリ使用を防ぐための設定です\n",
    "\n",
    "### 2. ソクラテス風の特徴定義\n",
    "```python\n",
    "socratic_patterns = {\n",
    "    'question_endings': ['かね', 'だろうか', 'ではないかね'],\n",
    "    'address_patterns': ['君は', '君が', '君の'],\n",
    "    'inquiry_leads': ['では', 'について']\n",
    "}\n",
    "```\n",
    "ソクラテス風の話し方の3つの特徴を定義：\n",
    "1. 質問の終わり方（例：「真実とは何かね？」）\n",
    "2. 相手への呼びかけ方（例：「君はどう考えるか？」）\n",
    "3. 問いかけの導入（例：「では、正義について考えよう」）\n",
    "\n",
    "### 3. 採点システム\n",
    "```python\n",
    "def calculate_socratic_style(text):\n",
    "    sentences = text.split('。')  # 文章を1文ずつに分割\n",
    "    scores = []\n",
    "    for sent in sentences:\n",
    "        # 各特徴の確認\n",
    "        ends_with_question = any(sent.endswith(p) for p in socratic_patterns['question_endings'])\n",
    "        uses_proper_address = any(p in sent for p in socratic_patterns['address_patterns'])\n",
    "        uses_inquiry_lead = any(p in sent for p in socratic_patterns['inquiry_leads'])\n",
    "        \n",
    "        # スコア計算（合計1.0になる重み付け）\n",
    "        sentence_score = (\n",
    "            (ends_with_question * 0.6) +  # 質問調の終わり方：60%\n",
    "            (uses_proper_address * 0.25) + # 「君は」などの使用：25%\n",
    "            (uses_inquiry_lead * 0.15)     # 「では」などの導入：15%\n",
    "        )\n",
    "        scores.append(sentence_score)\n",
    "```\n",
    "\n",
    "例えば、以下の応答をスコア化すると：\n",
    "\n",
    "> 「では、君は正義について何を考えているのかね？」\n",
    "\n",
    "- 「かね」で終わる → 0.6点\n",
    "- 「君は」を使用 → 0.25点\n",
    "- 「では」で導入 → 0.15点\n",
    "- 合計：1.0点（満点！）\n",
    "\n",
    "一方、以下の応答は：\n",
    "> 「正義は大切です。」\n",
    "\n",
    "- 質問調なし → 0点\n",
    "- 「君は」なし → 0点\n",
    "- 導入表現なし → 0点\n",
    "- 合計：0点（ソクラテス風ではない）\n",
    "\n",
    "### 4. 最終スコア計算\n",
    "```python\n",
    "style_scores = [calculate_socratic_style(pred) for pred in decoded_preds]\n",
    "final_score = np.mean(style_scores)\n",
    "```\n",
    "- 全ての応答文のスコアを計算し\n",
    "- その平均値を最終的な「ソクラテス度」として返します\n",
    "\n",
    "このスコアが高いほど、モデルがソクラテス風の話し方を上手く学習できていることを示します。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4.3 Training Callbacks\n",
    "# Custom callback modification\n",
    "class StyleCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.socratic_scores = []\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if 'eval_socratic_style' in metrics:\n",
    "            self.socratic_scores.append(metrics['eval_socratic_style'])\n",
    "            \n",
    "            # Log detailed information\n",
    "            logging.info(f\"Step {state.global_step}:\")\n",
    "            logging.info(f\"Socratic Style Score: {metrics['eval_socratic_style']:.3f}\")\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Log overall evaluation\n",
    "        avg_score = sum(self.socratic_scores) / len(self.socratic_scores) if self.socratic_scores else 0\n",
    "        \n",
    "        logging.info(\"Training Complete!\")\n",
    "        logging.info(f\"Average Socratic Style Score: {avg_score:.3f}\")\n",
    "\n",
    "# TrainingMonitorCallback also modified\n",
    "class TrainingMonitorCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_start_time = None\n",
    "        self.metrics_history = {\n",
    "            'step': [],\n",
    "            'socratic_style': [],  # Metric name changed\n",
    "            'loss': [],\n",
    "            'learning_rate': [],\n",
    "            'epoch': []\n",
    "        }\n",
    "        self.output_dir = Path(\"model/training_progress\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        self.train_start_time = datetime.now()\n",
    "        log_memory_usage()\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        # Record metrics\n",
    "        current_step = state.global_step\n",
    "        \n",
    "        # Record loss and learning_rate for all steps\n",
    "        if 'loss' in logs:\n",
    "            self.metrics_history['step'].append(current_step)\n",
    "            self.metrics_history['epoch'].append(state.epoch)\n",
    "            self.metrics_history['loss'].append(logs['loss'])\n",
    "            self.metrics_history['learning_rate'].append(logs.get('learning_rate', None))\n",
    "            self.metrics_history['socratic_style'].append(None)  # None for non-evaluation steps\n",
    "        \n",
    "        # Update socratic_style score in evaluation step\n",
    "        if 'eval_socratic_style' in logs:\n",
    "            # Update last entry (same step)\n",
    "            if self.metrics_history['step'] and self.metrics_history['step'][-1] == current_step:\n",
    "                self.metrics_history['socratic_style'][-1] = logs['eval_socratic_style']\n",
    "            else:\n",
    "                # Add new entry\n",
    "                self.metrics_history['step'].append(current_step)\n",
    "                self.metrics_history['epoch'].append(state.epoch)\n",
    "                self.metrics_history['loss'].append(None)\n",
    "                self.metrics_history['learning_rate'].append(None)\n",
    "                self.metrics_history['socratic_style'].append(logs['eval_socratic_style'])\n",
    "        \n",
    "        # Save to CSV file\n",
    "        df = pd.DataFrame(self.metrics_history)\n",
    "        df.to_csv(self.output_dir / 'training_metrics.csv', index=False)\n",
    "        \n",
    "        # Update graph every 100 steps\n",
    "        if current_step % 100 == 0:\n",
    "            self._plot_metrics()\n",
    "            \n",
    "    def _plot_metrics(self):\n",
    "        \"\"\"Plot learning metrics and save\"\"\"\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Plot Loss - Exclude None\n",
    "        plt.subplot(2, 2, 1)\n",
    "        valid_steps_loss = [s for s, v in zip(self.metrics_history['step'], self.metrics_history['loss']) if v is not None]\n",
    "        valid_loss = [v for v in self.metrics_history['loss'] if v is not None]\n",
    "        if valid_steps_loss:\n",
    "            plt.plot(valid_steps_loss, valid_loss, label='Loss')\n",
    "            plt.title('Training Loss')\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "        \n",
    "        # Plot Learning Rate - Exclude None\n",
    "        plt.subplot(2, 2, 2)\n",
    "        valid_steps_lr = [s for s, v in zip(self.metrics_history['step'], self.metrics_history['learning_rate']) if v is not None]\n",
    "        valid_lr = [v for v in self.metrics_history['learning_rate'] if v is not None]\n",
    "        if valid_steps_lr:\n",
    "            plt.plot(valid_steps_lr, valid_lr, label='LR')\n",
    "            plt.title('Learning Rate')\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.legend()\n",
    "        \n",
    "        # Plot Socratic Style Score - Exclude None\n",
    "        plt.subplot(2, 2, 3)\n",
    "        valid_steps = [s for s, v in zip(self.metrics_history['step'], self.metrics_history['socratic_style']) if v is not None]\n",
    "        valid_scores = [v for v in self.metrics_history['socratic_style'] if v is not None]\n",
    "        if valid_steps:\n",
    "            plt.plot(valid_steps, valid_scores, label='Socratic Style')\n",
    "            plt.title('Socratic Style Score')\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'training_progress.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Final learning result summary to save\n",
    "        summary = {\n",
    "            'training_duration': str(datetime.now() - self.train_start_time),\n",
    "            'final_loss': self.metrics_history['loss'][-1] if self.metrics_history['loss'] else None,\n",
    "            'best_socratic_score': max(filter(None, self.metrics_history['socratic_style'])) if self.metrics_history['socratic_style'] else None,\n",
    "            'total_steps': len(self.metrics_history['step']),\n",
    "            'final_epoch': self.metrics_history['epoch'][-1] if self.metrics_history['epoch'] else None\n",
    "        }\n",
    "        \n",
    "        # Save summary as JSON file\n",
    "        with open(self.output_dir / 'training_summary.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Final graph to save\n",
    "        self._plot_metrics()\n",
    "        \n",
    "        logging.info(\"Training Complete!\")\n",
    "        logging.info(f\"Training duration: {summary['training_duration']}\")\n",
    "        \n",
    "        # None check added\n",
    "        if summary['final_loss'] is not None:\n",
    "            logging.info(f\"Final loss: {summary['final_loss']:.4f}\")\n",
    "        else:\n",
    "            logging.info(\"Final loss: Not available\")\n",
    "        \n",
    "        if summary['best_socratic_score'] is not None:\n",
    "            logging.info(f\"Best Socratic style score: {summary['best_socratic_score']:.4f}\")\n",
    "        else:\n",
    "            logging.info(\"Best Socratic style score: Not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "この部分は、ソクラテス風チャットボットの学習過程を監視・記録するシステムです。2つの重要なクラスで構成されています：\n",
    "\n",
    "### 1. StyleCallback クラス\n",
    "```python\n",
    "class StyleCallback(TrainerCallback):\n",
    "```\n",
    "これは「ソクラテス度」の監視係です。\n",
    "\n",
    "例えば：\n",
    "- モデルが「君は正義について何を考えているのかね？」と返答 → 高スコア\n",
    "- モデルが「はい、そうですね」と返答 → 低スコア\n",
    "\n",
    "主な機能：\n",
    "- 評価時にソクラテス度スコアを記録\n",
    "- 学習終了時に平均スコアを計算\n",
    "- 結果をログに記録\n",
    "\n",
    "### 2. TrainingMonitorCallback クラス\n",
    "```python\n",
    "class TrainingMonitorCallback(TrainerCallback):\n",
    "```\n",
    "これは「学習の進捗管理係」です。以下の情報を追跡・記録します：\n",
    "\n",
    "1. **基本情報の記録**\n",
    "```python\n",
    "self.metrics_history = {\n",
    "    'step': [],          # 学習ステップ\n",
    "    'socratic_style': [], # ソクラテス度\n",
    "    'loss': [],          # 損失値\n",
    "    'learning_rate': [], # 学習率\n",
    "    'epoch': []          # エポック\n",
    "}\n",
    "```\n",
    "\n",
    "2. **グラフの作成** (`_plot_metrics`メソッド)\n",
    "3つのグラフを作成：\n",
    "- 損失値の推移（モデルの改善度）\n",
    "- 学習率の変化\n",
    "- ソクラテス度スコアの推移\n",
    "\n",
    "例えば：\n",
    "```\n",
    "Step 100:\n",
    "- 損失値: 2.5\n",
    "- ソクラテス度: 0.3\n",
    "（まだソクラテスらしくない）\n",
    "\n",
    "Step 1000:\n",
    "- 損失値: 1.2\n",
    "- ソクラテス度: 0.7\n",
    "（だいぶソクラテスらしくなってきた）\n",
    "\n",
    "Step 2000:\n",
    "- 損失値: 0.8\n",
    "- ソクラテス度: 0.9\n",
    "（かなりソクラテスらしい応答ができるように）\n",
    "```\n",
    "\n",
    "3. **最終結果のまとめ** (`on_train_end`メソッド)\n",
    "```python\n",
    "summary = {\n",
    "    'training_duration': 学習にかかった時間,\n",
    "    'final_loss': 最終的な損失値,\n",
    "    'best_socratic_score': 最高のソクラテス度,\n",
    "    'total_steps': 総ステップ数,\n",
    "    'final_epoch': 最終エポック\n",
    "}\n",
    "```\n",
    "\n",
    "これらの情報は：\n",
    "- CSVファイルとして保存\n",
    "- グラフとして視覚化\n",
    "- JSONファイルとしてまとめられる\n",
    "\n",
    "このシステムのおかげで：\n",
    "1. 学習がうまくいっているか常に確認できる\n",
    "2. モデルがどれだけソクラテスらしくなったか追跡できる\n",
    "3. 問題があればすぐに気付ける\n",
    "4. 学習結果を後で分析できる\n",
    "\n",
    "例えるなら、料理人（開発者）が：\n",
    "- 味の変化（ソクラテス度）を記録\n",
    "- 火加減（学習率）を調整\n",
    "- 調理時間（学習時間）を管理\n",
    "- 最終的な出来栄えを評価\n",
    "するようなものです。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Custom Trainer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4.4 Custom Trainer Implementation\n",
    "class CustomTrainer(Trainer):\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        loss = super().training_step(*args, **kwargs)\n",
    "        if self.state.global_step % 100 == 0:\n",
    "            clear_memory()\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
    "        if eval_dataset is not None:\n",
    "            # Limit evaluation dataset to 100 samples\n",
    "            eval_dataset = eval_dataset.select(range(min(100, len(eval_dataset))))\n",
    "        return super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "このCustomTrainerクラスは、学習プロセスをカスタマイズするための特別な実装です。2つの重要な機能を持っています：\n",
    "\n",
    "### 1. 学習ステップの管理 (`training_step`メソッド)\n",
    "```python\n",
    "def training_step(self, *args, **kwargs):\n",
    "    loss = super().training_step(*args, **kwargs)\n",
    "    if self.state.global_step % 100 == 0:\n",
    "        clear_memory()\n",
    "    return loss\n",
    "```\n",
    "\n",
    "これは「定期的な大掃除」のような機能です：\n",
    "\n",
    "- 100ステップごとにメモリを掃除します\n",
    "- 例えば：\n",
    "  1. 100個の対話を学習\n",
    "  2. メモリを掃除\n",
    "  3. また100個の対話を学習\n",
    "  4. メモリを掃除\n",
    "  ...という具合\n",
    "\n",
    "これにより：\n",
    "- メモリ不足を防ぐ\n",
    "- 学習の安定性を保つ\n",
    "- システムの動作を快適に保つ\n",
    "\n",
    "### 2. 評価の効率化 (`evaluate`メソッド)\n",
    "```python\n",
    "def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "    eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
    "    if eval_dataset is not None:\n",
    "        # Limit evaluation dataset to 100 samples\n",
    "        eval_dataset = eval_dataset.select(range(min(100, len(eval_dataset))))\n",
    "    return super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "```\n",
    "\n",
    "これは「効率的な品質チェック」のような機能です：\n",
    "\n",
    "- 評価用データを最大100サンプルに制限\n",
    "- 例えば：\n",
    "  - 全部で1000個の評価用対話データがあっても\n",
    "  - 実際の評価には100個だけを使用\n",
    "  - これでも十分な評価が可能\n",
    "\n",
    "理由：\n",
    "1. 評価が速くなる\n",
    "2. メモリ使用量を抑えられる\n",
    "3. それでも十分な精度で「ソクラテス度」を測定できる\n",
    "\n",
    "具体例：\n",
    "```\n",
    "評価データ：\n",
    "user: 「正義とは何でしょうか？」\n",
    "model: 「君は正義とは何だと考えるかね？」\n",
    "\n",
    "user: 「幸せについて考えています」\n",
    "model: 「では、君にとって幸せとは何かね？」\n",
    "\n",
    "...（このような対話を100個サンプリング）\n",
    "```\n",
    "\n",
    "このように、効率的な学習と評価を実現し、限られたリソースで最大の効果を得られるように工夫されています。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4.5 Training Setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model\",\n",
    "    num_train_epochs=30,     \n",
    "    learning_rate=8e-5,      \n",
    "    weight_decay=0.06,         \n",
    "    warmup_ratio=0.25,         \n",
    "    lr_scheduler_type=\"cosine_with_restarts\",  \n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,            \n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    gradient_accumulation_steps=8,   \n",
    "    max_steps=-1,\n",
    "    disable_tqdm=False,\n",
    "    logging_dir=\"./model/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    no_cuda=False,\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=[],\n",
    "    run_name=None,\n",
    "    per_device_train_batch_size=4,  \n",
    "    per_device_eval_batch_size=2,  \n",
    "    gradient_checkpointing=True,\n",
    "    max_grad_norm=0.5,       \n",
    "    dataloader_pin_memory=True,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    eval_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"socratic_style\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "pre {\n",
    "    border: 1px solid #333;\n",
    "    padding: 20px;\n",
    "    margin: 20px 0;\n",
    "    background-color: #000000;\n",
    "    color: #d4d4d4;\n",
    "    border-radius: 8px;\n",
    "}\n",
    "pre code {\n",
    "    color: #d4d4d4;\n",
    "    display: block;\n",
    "    padding-bottom: 8px;\n",
    "    background-color: #000000; \n",
    "}\n",
    "\n",
    ".hljs, .language-python {\n",
    "    background-color: #000000 !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div style=\"background-color: #F9F4F0; padding: 10px; border-left: 5px solid #4CAF50; margin: 10px; width: 95%;\">\n",
    "    <details>\n",
    "        <summary style=\"color: #8A6F5C; font-size: 1.17em; font-weight: bold;\">claude解説</summary>\n",
    "        <div style=\"color: #8A6F5C;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "この部分は、ソクラテス風チャットボットの学習に関する具体的な設定を定義しています。重要なパラメータを順に説明します：\n",
    "\n",
    "### 1. 基本的な学習設定\n",
    "```python\n",
    "output_dir=\"./model\",           # 学習結果の保存場所\n",
    "num_train_epochs=30,           # 全データを30周学習\n",
    "learning_rate=8e-5,            # 学習率（どれくらい大きく更新するか）\n",
    "```\n",
    "\n",
    "例えるなら：\n",
    "- 30回同じ教材（データ）を繰り返し学習\n",
    "- 少しずつ慎重に学習（小さな学習率）\n",
    "\n",
    "### 2. 学習の進め方\n",
    "```python\n",
    "warmup_ratio=0.25,             # 準備運動期間（全体の25%）\n",
    "lr_scheduler_type=\"cosine_with_restarts\",  # 学習率の変化パターン\n",
    "evaluation_strategy=\"steps\",    # 20ステップごとに評価\n",
    "eval_steps=20,\n",
    "```\n",
    "\n",
    "例えるなら：\n",
    "1. まず準備運動（徐々に学習率を上げる）\n",
    "2. 本格的な学習（最適な学習率で学習）\n",
    "3. 定期的に「ソクラテス度」をチェック\n",
    "\n",
    "### 3. バッチサイズ設定\n",
    "```python\n",
    "per_device_train_batch_size=4,  # 一度に学習する対話数\n",
    "per_device_eval_batch_size=2,   # 一度に評価する対話数\n",
    "```\n",
    "\n",
    "具体例：\n",
    "```\n",
    "バッチ1:\n",
    "user1: 「正義とは何でしょうか？」\n",
    "model1: 「君は正義とは何だと考えるかね？」\n",
    "\n",
    "user2: 「幸せについて考えています」\n",
    "model2: 「では、君にとって幸せとは何かね？」\n",
    "\n",
    "（このように4組の対話を一度に学習）\n",
    "```\n",
    "\n",
    "### 4. メモリと性能の最適化\n",
    "```python\n",
    "gradient_accumulation_steps=8,  # 8回分の計算をまとめて更新\n",
    "gradient_checkpointing=True,    # メモリ効率を重視\n",
    "fp16=True,                      # 16ビット精度で計算（メモリ節約）\n",
    "```\n",
    "\n",
    "これにより：\n",
    "- メモリ使用を抑えつつ\n",
    "- 効率的に学習を進められる\n",
    "\n",
    "### 5. モデルの保存設定\n",
    "```python\n",
    "save_strategy=\"steps\",          # 20ステップごとに保存\n",
    "save_steps=20,\n",
    "save_total_limit=3,            # 最新3つのモデルを保持\n",
    "load_best_model_at_end=True,   # 最もソクラテスらしいモデルを採用\n",
    "metric_for_best_model=\"socratic_style\",  # ソクラテス度で評価\n",
    "```\n",
    "\n",
    "例えば：\n",
    "1. 20ステップ目：ソクラテス度0.5のモデルを保存\n",
    "2. 40ステップ目：ソクラテス度0.7のモデルを保存\n",
    "3. 60ステップ目：ソクラテス度0.6のモデルを保存\n",
    "→ 最終的にソクラテス度0.7のモデルを採用\n",
    "\n",
    "このように、効率的かつ効果的な学習を実現するための詳細な設定が行われています。\n",
    "\n",
    "        \n",
    "</div>\n",
    "    </details>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
