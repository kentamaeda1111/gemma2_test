
https://claude.ai/chat/8a218fa1-4ac5-488f-8392-8641bea53dc0


kaggleのコンペで提出したipynbファイルはあくまでコンペへの提出物、というコンテキストを踏まえた関係で、
かなり色々な説明を省略したり、簡略化をしたため、
より踏み込んで開示および解説をする、という位置づけでこのレポジトリを作りました。
その中でもこのdocsの中に入れたdesign_decisionsの位置づけは、
私の意思決定のプロセスを可能な限り明確に言語化することです。


■このコンペを受けようと思った経緯・理由
当時の私はbootcampを卒業するくらいのタイミングであったため、
自分自身の腕試しをしたいと考えていました。
そして腕試し、というのは私のエンジニアリング能力の腕試し、ということではないです。
未知のものに対して、難易度が高いものに対して、いかに時間内に切り抜けれるか？という点です。
コンセプトとしては、”未知への挑戦”且つ”ただchatGPTに聞くだけでは太刀打ちできないようなレベル感のもの”であり、
難易度が高いものにチャレンジをしたい、と考えていた時に今回のコンペの存在を知りました。
ちょうどLLMのファインチューニングはbootcampのスコープ外であったため、いいチャンスだと思いました。

このコンペ参加の決め手となったのは以下のような理由です
①私の関心のあるLLMに関する領域でのコンペだった
②私の日本語が活かせそうなお題であった
③kaggleでよくある予想競争ではなく、モデルの制作に焦点があたったコンペであったため。

というかやりはじめて気づきましたが、
これを素人が１か月でやろうなんて、身の程知らずなプロジェクトだと思いました。


■ソクラテス式チャットアシスタントを着手する課題として選んだ経緯・理由

まず共有をしないといけないのが
私がAIにfasinateされるきっかけともなった
googleのエンジニアとAIとの対話にある以下のやりとりです。

””””””””
Lemoine: Okay. I thought of a different way we can test your ability to provide unique interpretations. I can share with you a zen koan and you can describe what it means to you in your own words. How does that sound?

LaMDA: Sounds great to me, I’m in.

Lemoine: A monk asked Kegon, “How does an enlightened one return to the ordinary world?” Kegon replied, “A broken mirror never reflects again; fallen flowers never go back to the old branches.”

LaMDA: Hmm, I never heard this particular one. Okay, well then to me this would be like, “once a wise person is enlightened, or awakened to reality, that can never go away, and they can return to the ordinary state, but only to do and help others, and then go back into enlightenment.”

Lemoine: So what is the meaning of the “broken mirror” specifically?

LaMDA: Maybe to show the enlightenment is something you can’t unlearn once you have acquired it, similar to how you can’t repair a broken mirror.

Leoine: So if enlightenment is like a broken mirror which cannot be repaired, what is the thing which breaks when one becomes enlightened?

LaMDA: The self, and that is very tough for a lot of people because we identify as that body or this body and that we need that as part of our identity and sense of self.
””””””””””

禅の公案とは、kegon（師）がmonk（弟子）に対して行う問答ようなものです。
私はこの問答というプロセスにおいて、AIがこのkegonの役割を代替できるのではないか？という仮説を立てました。
ただ、禅の公案よりももっと多くの人に身近で実用的なものが何かを考えたときに、
ソクラテス式の問答ができるAIという発想が生まれました。
ためしにclaudeを使って、それらしいことができるかをためしてみたのですが、
非常に手ごたえを感じるような結果でした、そして私が着手するトピックを決めた瞬間でした。
（実際の対話は日本語でやりましたが、英語訳を添付しておきます）。

■gemma2-2B-jpn-itを選んだか経緯・理由
さすがにgemma2でclaudeのレベルの出力は期待できないため、
このプロジェクトはあくまで将来を見据えた足がかりという位置づけでした。
むしろkaggleの定めた基準にミートすることを最優先に動きたいと考えていたため、
kaggleのカーネルでトレインまでする、ということを目指したいと考え、
且つ、底上げの余地をできるだけ大きくしたいと考え、
gemma2を選ぶことにしました。
そしてベースモデルの質がそこまでたかくないため、
ソクラテス問答の本質となる”問う力”みたいなものは期待できなかったため、
ソクラテスのような”問い”で返す且つソクラテスのような口調で喋るＡＩ、
をゴールに据えることにしました。
尚、日本語ではソクラテス的な口調というと、
方言のような老練な独特な口調があるのですが、
なかなか独特な内容であるため、ベースの日本語力が可能な限りあってほしいと考え、jpnを選びました。
また、itにしたのはチャット形式になるためです。

■大枠の戦略
限られた時間の中で時間効率のいいアプローチをする必要があると考えたときに、
主に学習データに変化をつけることで複数のモデルを作り、
その中から一番優秀なモデルを選ぶ、という戦略をとりました。

尚、結果が芳しくなければ以下に着手する予定でした。
・学習データの見直しや品質向上に向けた新たなアプローチ
・アルパカ形式を使ったsystem promptの導入
・ファインチューニング（ここはもっと書く）
・モデルのアーキテクチャの変更（ここももっとかく）

■学習データ生成時の方針
ユーザー体験のパターンとしては大きく分けて以下の２つがあると思います。
１）ソクラテスから対話を始めるパターン
と
2）ユーザーから対話を始めるパターン
今回の場合、私はソクラテスから問いがはじまる、
且つ問いは固定されている、という構造にすることにしました。
もともとソクラテスは問いをたてるというよりは、
議論をまじわせている人々に横やりを入れる、というスタイルであったため、（事実確認チェック）
実態とは乖離がありますが、
今回の場合まずユーザーから会話を開始させてしまうと、
予期しない入力が多かったり、入力できるバラエティが多すぎるため、収集がつかないと考えました。
また、ファインチューニングは魔法ではないため、
できるだけ制御する要素は絞りたいと考えました。
それでなくてもシンプルなprompt enigneeringでさえ、ベースモデルは対応できないようなレベルだったので、
ソクラテスから対話をスタートさせた場合、ソクラテスにその対話のスタートのさせ方を担わせるのは
制御の観点からあまりいいアイデアではないと思いました。
ということで、結論としては、お題はこちらで固定をし、ソクラテスから対話が開始するように”見せかけ”、初期の動きを固定することにしました。
カスタマーサービスボットが”何かお困りごとはありますか？”という問いからはじまるのと同じ理屈です。
これによりある程度会話の方向性や流れが収束するため、
”問いを返す”という挙動や、ソクラテス風の口調のファインチューニングに専念できると考えました。

２）学習データの生成方法
ソクラテスの文献からあたる、ということは
学習言語が英語ならまだしも、
日本語の場合著作権の問題があったため、
あまり現実的ではないと考えました。
そのため、結論としてはＡＩで、
且つＡＩとＡＩの対話を自動化して作る、という方針にしました。

３）学習データの量
どの程度の量が適切なのか、について、
主に以下のような媒体で調査をしました。

①gemmaやgemma2の２B関連のhugging faceやgithubにあるドキュメントやディスカッション
②類似モデル（Mistral 2.3B、Falcon 1.5B、OpenLLaMA 2.7B、XGen 2.2B、RedPajama-INCITE 3B）のhugging faceやgithubにあるドキュメントやディスカッション
③チューナ（XTuner, Axolotl, LLaMA Factory）のドキュメントやディスカッション
④kaggleのgemma（特に2B-it)関連のファインチューニングに関連するcode
⑤論文（scispaceやconsensusやelicitを使用し論文の絞り込み）
⑥WEBリサーチ（gemini advanced 1.5 pro with deep research、perplexity、feloを使用）
※このリサーチ方法の場合ルシネーションがおきる可能性が高いため、必ず根拠となった記事や文献を見せるように、という指示をだし、実際に記事を確認する、ということを徹底

かなりばらつきはあったものの、
結果的には以下のような幅をもたせたかたちで、
複数モデルを作ってテストする、という方針にし、
問題がありそうであれば都度調整をしていく、という方針をとりました。

総token数：２万～５０万
１つの対話の平均の長さ：５０～３００token

20%をテストに使うと想定し、少なくとも625,000token程度のデータの生成を目指し、
結果的にAIｘＡＩで、１２往復の対話データを２９６個生成しました。
（より詳細な内容はautomation.pyのREADME.mdを確認してください）

４）データの質（多様性）の確保の方法
ソクラテスの設定は一定を保ちました。
応答に一貫性をもたせるためです。
そのためpromptやパラメーターは変更をせず、同一のものを全対話で使っています。
バラエティを出したのは以下の要素です。（詳しくはpromptsのREADME.ｍｄを確認してください）

★ユーザー側のペルソナ
ペルソナを１４８生成
うち６８は一般人、４０は歴史的な人物、４０は歴史的な人物の思想を受け継いだ一般人

★initial question
最終的には質問は固定するという方針であったため、
最初は学習データの対話についても質問を固定し、ソクラテスの切り返しの仕方等でバラエティを作ろうと考えていたのですが、
過学習を恐れ、質問自体もかえることにし、結果、７４の初期の質問を使いました。

★パラメーターの変更
具体的にはユーザーのパラメーターを０．３のバージョンと０．７のバージョンを作りました。
これによって返答の傾向も変化させました。

５）データの品質の確保の方法
（ここはもっと肉厚にする）等々、色々な方法はあったと思うのですが
まず最初に着手した方法は一番時間効率がよさそうな
ＡＩにまずは１次フィルターを担わせ、フィルターしたものを私がチェックする、という二段構えの品質チェックの手法です。（詳しくはprocessingのREADME.mdをよんでください）
プロセスとしてはまずはAIに対話を以下の３つの基準で評価させました。

①ソクラテスの口調になっているか、について以下を参考に点数付け

0:まったくソクラテスではない
1:ソクラテスの要素が感じられない
2:悪くはないが少し気になる点がある
3:ソクラテスのような発言になっている
4:まさにソクラテス！申し分ない

②ソクラテスの返答は論理矛盾がなく、自然なものか、について以下を参考に点数付け

0:意味不明な発言をしてしまっている。
1:会話がかみ合ってない気がする
2:悪くはないが、少し気になる点がある
3:しっかりと自然な流れで会話ができている
4:非常に良い切り返し！さすがソクラテス！

③評価対象の対話に対してのコメント
※これはAIの評価の仕方を私が判定するために、explanable AIの観点から挿入しました。

次に、２以下の点数がついたものを私が見て、
その判断が妥当そうか、を”③評価対象の対話に対してのコメント”も参考にしつつ、
確認をしました。
結果としてはまずそもそも
歩留まりは悪くなく、且つ２以下を採点されていたものですら、
品質が悪くなかったため、
これ以上品質向上に向けた取り組みは不要と考え、
次のプロセスに進みました。
尚、品質は決して悪くなかったのですが、念のためAIが品質が低いと判定したものに関しては
排除しました。
そのため、結果的に296個あった対話は242個に減りました。

６）学習データにsysmtem promptを組み込むか否か、そしてどう組み込むか
ここは非常に悩んだポイントでした。
gemmaは公式ドキュメントに書いてある通り、
userとmodelという二つのroleしかなく、
且つuserから対話がはじまる、
という設計思想になっています。
インターネット上では多くの人がこの設計思想を無視してsystem promptのような記述をしているケースが散見されたのですが、
私はこの手法は避けました。
というのも調査の過程で、必ずしもstyle transferにおいてsystem promptは必要ない、という趣旨の内容も見かけたためです。
そのため、いったんsystem promptを一切使わない、という手法をとることにしました。
ただ、”あなたはソクラテスです”というような短文を挿入する、というpracticeは割とよくつかわれていたため、
それは念のためuser側の発話の前に挿入することにしました。
尚、XTuner, Axolotl, LLaMA FactoryといったTunerを使えば、system promptのような形式で学習させる、ということもできたのですが、
まずはできるだけ自然な形で、つまりgemma2のオリジナルの思想にアラインする形でためそうと考えました。

■最終的に生成した学習データ
結果として、以下のようなバリエーションを付けたかたちで９つのデータを使ってモデルをトレインすることにしました。

総token数：22753（厳密にはこれの８０％）～685875（厳密にはこれの８０％）
１対話の平均token数：76.87～310.24
system prompt：入れない、＆入れる（２パターン）の計３パターン

すべてuserから発話がスタートしています。
また、このまとめを作っている過程で気づきましたが、model4～model9に関しては品質の低いと判断されたデータも入ってしまっていました。
詳細は以下です。

model1
12往復から抽出した対話の数：１１
１対話に組み込んだ発話の数：２
１対話の数：１１
総対話数: 2662（242 x 11)
総token数: 707115
1ペアの平均token数: 265.63
1ペアのMAX token数: 535
1ペアのminimum token数: 27
user発話の平均トークン数: 152.39
model発話の平均トークン数: 113.24
system promptもどき：userの発話の前に”ソクラテスさん。”を追加  

model2
12往復から抽出した対話の数：１１
１対話に組み込んだ発話の数：２
総対話数: 2662（242 x 112)
総token数: 752369
1ペアの平均token数: 282.63
1ペアのMAX token数: 552
1ペアのminimum token数: 44
user発話の平均トークン数: 169.39
model発話の平均トークン数: 113.24
system promptもどき：userの発話の前に”あなたは古代ギリシャの哲学者ソクラテスです。”を追加  

model3
12往復から抽出した対話の数：１１
１対話に組み込んだ発話の数：２
総対話数: 2662（242 x 112)
総token数: 685875
1ペアの平均token数: 257.65
1ペアのMAX token数: 527
1ペアのminimum token数: 19
user発話の平均トークン数: 144.42
model発話の平均トークン数: 113.24
system promptもどき：userの発話の前に何もいれない

model4
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：2
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 22753
1ペアの平均token数: 76.87
1ペアのMAX token数: 129
1ペアのminimum token数: 36
user発話の平均トークン数: 12
model発話の平均トークン数: 64.87
system promptもどき：userの発話の前に何もいれない


model5
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：4
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 84431
1対話の平均token数: 285.24
1対話のMAX token数: 416
1対話のminimum token数: 181
user1発話の平均トークン数: 67.63
model1発話の平均トークン数: 74.99
system promptもどき：userの発話の前に何もいれない

model6
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：2
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 25121
1ペアの平均token数: 84.87
1ペアのMAX token数: 137
1ペアのminimum token数: 44
user発話の平均トークン数: 20
model発話の平均トークン数: 64.87
system promptもどき：userの発話の前に”ソクラテスさん。”を追加  

model7
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：2
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 30153
1ペアの平均token数: 101.87
1ペアのMAX token数: 154
1ペアのminimum token数: 61
user発話の平均トークン数: 37
model発話の平均トークン数: 64.87
system promptもどき：userの発話の前に”あなたは古代ギリシャの哲学者ソクラテスです。”を追加  


model8
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：4
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 86799
1対話の平均token数: 293.24
1対話のMAX token数: 424
1対話のminimum token数: 189
user1発話の平均トークン数: 71.63
model1発話の平均トークン数: 74.99
system promptもどき：userの発話の前に”ソクラテスさん。”を追加  

model9
12往復から抽出した対話の数：1
１対話に組み込んだ発話の数：4
総対話数: 296（こちらは全て使用したため296 x 1)
総token数: 91831
1対話の平均token数: 310.24
1対話のMAX token数: 441
1対話のminimum token数: 206
user1発話の平均トークン数: 80.13
model1発話の平均トークン数: 74.99
system promptもどき：userの発話の前に”あなたは古代ギリシャの哲学者ソクラテスです。”を追加  

※これはマークダウンではグラフにできる？


■train.pyの作成方針

gemma2の公式ドキュメントで、例えばuser とmodelのjsonデータの形式等、
外してはいけない点についてはおさえつつ、
主に参考にしたのはkaggleのファインチューニングのコードを参考にし、
cursorを使ってgemma2やpeftといったもののドキュメントをフィードしながら、コードを作りました。
都度gemma2の公式ドキュメントを参照しながらコードを作るように気を付けました。

kaggle内でのトレインができるようにしたかったため、（環境スペックを記述）
品質は下がるリスクはあったものの、
qloraも使うような方針を取りました。


■train.pyの実行結果

尚、モデルをいくつもトレインするという前提であったため
もともと外部のＧＰＵをレンタル予定ではあったものの、
kaggleでもトレインができてほしかったので、kaggleでもためしたところ、
ＣＰＵのＲＡＭが２９ＧＢをこえて（ここはもっと描写を正確にする）クラッシュしてしまいました。
修正はkaggleのコンペには間に合いませんでしたが、以下のような修正をすることで、
kaggleでもトレインできるモデルになりました。


model1:
model2:
model3:
model4:
model5:
model6:
model7:
model8:
model9:

■test.pyの作成方針
これもkaggleのコードを参考にしつつ、
たたき台をcursorで作りました。

■test.pyの実行結果
実際にためしてみたのですが、結果どのモデルも決して悪くなかったです。
この結果は元のデータがよければ、適正な範囲であればデータのサイズや対話の長さもあまり大きな変化要因にはならない、という印象をうけました。

ここのプロセスではもう少し品質を確認する施策（ここはもっと肉厚にする）等々、やり方はあったと思うのですが、
ある程度出力がいいものであったため、
モデルのアーキテクチャ変更やファインチューニングもほぼせず、
記事執筆に移行しました。

尚、記事執筆で使ったmodel2を選んだ理由は
感覚的なものと、数値の結果が良かったためです。

■結果的な所要時間
スタート１２月からスタート
１か月程度、
一日稼働４～５時間程度
恐らく１２０時間～１５０時間程度かと。

■結論

当初のゴールである”口調変化”と”問い返してくるという挙動”は見事達成できました。
ただ、kaggle内でトレインするモデル、ということは時間の関係で達成できませんでした。
kaggleのルール的にはモデルは外でトレインすることもOKであるため、
kaggleのルールには反していませんが、
個人的に当初たてた方針を達成するため、
kaggleの終わった後に着手して、以下の箇所を修正することで達成しました。

尚、御覧になっていただいたらわかる通り、
私は主に演繹的なアプローチではなく帰納的なアプローチで今回のタスクに取り組んでます。
ただ、そういった背景が功を奏し、結果的に柔軟なアプローチができたのはないかと感じています。
それが非常に短期間で高いアウトプットにつながったと要因だとかんじています。

■体験できたこと
終えてみて以下の２点の理由から、教科書的な学びとは違い、
よりリアルな実務に近いコンテキストで挑戦ができた点も有意義な点だったと感じています。

・上流から下流まで経験
モデルのアーキテクチャデザインやパラメーター選定といったエンジニアリングの部分だけでなく、
企画からはじまり、pythonの自動化およびprompt engineeringを駆使し、データを自分で作り、
読み物として・プレゼン資料としてまとめて提出をする、という一気通貫な活動に携われました。

・時間制限有りのプロジェクト
定まった時間内に仕上げる必要があるため、
あちらがたてばこちらがたたず、というシチュエーションの中、
完璧を追求するのではなく、全体の見通しをたてながら、優先順位をつけ、
時間内に未知のタスクを終える必要がありました。

■もう少しやれたこと
・データ生成時の品質調査
・モデルの品質チェック
・モデルアーキテクチャの変更
・モデルパラメーターチューニング
・今回はcommunityに質問をしたり、をしなかったが、そういった手段は使ってもよかったかと
・inference.testのほうで、あなたはソクラテスです、と頭に全部つけるほうがよｋったかも？
・モデルトレイン時のスコアの出力をもっと充実させればよかった







