次は## 5. Evaluation Metrics for Fine-tuningにすすみましょう。繰り返しになりますが、gemma 2の2bモデルという規模間のモデルで且つソクラテス風の口調のチャットボット、を目指していた、というのがありまして、ソクラテス的な問答という問い力、のような深いレイヤーのものではなく、口調というわりとレイヤーの浅いものを目指していた、という大前提があるのですが、fine tuning時の評価指標については@train.py のコードのような方針をとったのですが、添付のコードの方向性を正当化するような論文はありそうですか？@5.5 @5.1 @5.2 @5.3 


添付や以下は評価基準には関係ないですか？

            conjunctions = ['しかし', 'だから', 'また', 'そして', 'したがって']