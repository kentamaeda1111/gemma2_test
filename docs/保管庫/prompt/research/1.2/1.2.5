5. Adapting Language Models for Non-Parallel Author-Stylized Rewriting
Bakhtiyar Syed, Gaurav Verma, Balaji Vasan Srinivasan, Anandhavelu Natarajan, Vasudeva Varma  




Introduction
The research paper addresses the emerging interest in studying style in natural language, focusing on tasks such as genre classification, author profiling, sentiment analysis, and social relationship classification. Recently, there has been a surge in stylized text generation and style transfer tasks aimed at aligning generated text with a target style, particularly in terms of sentiment and formality levels. This interest has led to the creation of annotated and parallel datasets featuring paired realizations across different style dimensions.

Key Points:
Tasks like genre classification, author profiling, and sentiment analysis have garnered significant research interest.
Stylized text generation and style transfer tasks are gaining traction in aligning text with a desired style.
The research aims to generate text across author styles, moving beyond psycholinguistic aspects to consider the amalgamation of an author's linguistic choices.
A novel framework is proposed for author-stylized rewriting that does not rely on parallel data, eliminating scalability issues.
The approach involves pre-training a language model on author corpus and Wikipedia data, followed by fine-tuning on a specific target author's corpus to adapt to their style.
The authors address the challenge of evaluating the stylistic alignment of rewritten text to a target author's style, proposing an interpretable framework that quantifies alignment at lexical, syntactic, and semantic levels. The research demonstrates improved performance over existing baselines, both qualitatively and quantitatively, showcasing significant advancements in author-stylized text generation without the need for parallel data.

Contributions:
Introduction of an approach for author-stylized text generation without relying on parallel data by leveraging state-of-the-art language models.
Proposal of an evaluation framework that assesses alignment of stylistic aspects, accounting for lexical and syntactic elements.
Demonstrated enhancement in author-stylized text generation compared to existing methods through qualitative and quantitative evaluations.
Related Work
The section delves into various approaches and methods in the domain of stylized text generation, focusing on generating author-stylized text. Here are the key points:

Stylized Text Generation:

Approaches range from supervised to unsupervised, including utilizing classification-based discriminators, linguistic rules, and auxiliary modules for scoring generation processes.
Challenges in building classification-based discriminators and linguistic-rule based generations for author-stylized text due to the complexity and unavailability of extensive rule sets.
The adoption of state-of-the-art language models for generating author-stylized text from non-parallel data is motivated by the fact that stylistic rewriting fundamentally involves text generation.
Language Models:

Generative pre-training of sentence encoders based on Transformer models has shown remarkable improvements in various natural language tasks.
Extending generative pre-training to learn cross-lingual language models has been explored by researchers.
The language model GPT-2, pre-trained on a diverse dataset, demonstrates strong performance in natural language generation but faces challenges in content preservation during stylistic rewriting.
Evaluating Stylized Generation:

Existing evaluation frameworks assess style transfer models on content preservation and transfer strength axes.
Challenges in evaluating author-stylized text due to the lack of well-established metrics for transfer strength in unsupervised approaches.
The proposal of a linguistically-aware evaluation framework to quantify alignment of lexical and syntactic aspects of style in generated text with the target author's style addresses this evaluation gap.
Proposed Approach: StyleLM
The researchers present a novel approach called StyleLM, which involves pre-training a Transformer-based language model on a large dataset and then fine-tuning it on an author-specific corpus using a DAE loss to enable stylized rewriting. Here are the key points of their proposed approach:

Pre-training Phase:

Utilizes a Transformer-based language model trained on a large unsupervised corpus with the masked language modeling (MLM) objective.
The Transformer architecture is chosen for its success in language modeling and bidirectional context understanding.
The pre-training involves predicting masked words to learn the language model parameters.
Fine-tuning Phase:

Involves cascading two instances of the pre-trained LM in an encoder-decoder setup for style-related fine-tuning.
The encoder predicts masked words while the decoder reconstructs the clean version of the noisy input text, inducing the target author's style.
Fine-tuning is done using the DAE (Denosing Autoencoder) loss function.
Implementation Details:

Pre-training uses a 12-layer Transformer encoder with specific configurations and GELU activations.
Training is done with the Adam optimizer, a learning rate of 10^-4, and specific batch sizes and token streams.
Fine-tuning on a target author involves reconstructing input passages from their noisy versions using the pre-trained model with the same hyperparameters.
Vocabulary Handling:

Byte Pair Encoding (BPE) is employed to manage the vast vocabulary size, learning 80k BPE codes on the combined training dataset of 141 authors.
The use of BPE allows scaling for any author in the Gutenberg corpus or beyond, enhancing adaptability and generalization capabilities.
Evaluation Framework
The researchers collated a subset of the Gutenberg corpus to fine-tune the encoder-decoder framework from a pretrained LM, focusing on 10 target authors for author-stylized text generation. The chosen authors include Sir Arthur Conan Doyle, Charles Dickens, and others. Key points included:

Dataset: A subset of 10 authors from the Gutenberg corpus was used as target authors.
Fine-tuning: Independently fine-tuned for each of the 10 target authors.
Inference Data: For test-time inference, source sentences were obtained from texts by Mark Twain, Opinosis Review dataset, and a specific Wikipedia article on AI.
Diverse Writing Styles: The sources span a range of topics and styles, providing varied linguistic input for evaluation.
Baselines: The researchers evaluated their approach against four baselines, including vanilla GPT-2 based generation, author fine-tuned GPT-2, Denoising-LM without author-specific fine-tuning, and Supervised Stylized Rewriting.
The framework involved testing against baselines trained on non-parallel data and one using parallel data for generating "Shakespearized" text. The baselines and the fine-tuned models were compared based on their output texts for evaluation.

Proposed Evaluation Methodology
The evaluation of the proposed frameworks in this study focuses on two key aspects: content preservation and stylistic alignment, utilizing existing techniques from style transfer and text generation literature. Here's a breakdown of the evaluation methodology:

Content Preservation Evaluation:

Measure the extent to which the generated stylized outputs retain the same meaning as the original input.
Evaluation metrics used: BLEU metric and ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-3, and ROUGE-L).
Stylistic Alignment Quantification:

Introduces a unique linguistic-motivated approach to quantify how well the generated text aligns stylistically with the target style.
Challenges in applying existing sentiment and formality transfer evaluation criteria due to the nuanced nature of author style.
Formulates a multi-level evaluation scheme inspired by Verma and Srinivasan (2019) to assess stylistic alignment at surface, lexical, and syntactic levels.
Utilizes standard distance metrics to measure alignment with the target style.
Quantifying Lexical Style Elements:

Styles at the word-level such as subjective vs. objective, concrete vs. abstract, literary vs. colloquial, formal vs. informal are considered.
Uses seed words for each style category and calculates raw style scores using normalized pointwise mutual information index (PMI).
Normalizes raw scores into style vectors, constructs k-Nearest Neighbor (kNN) graphs, and applies label propagation.
Computes averages across the author-specific corpus to determine the propensity of using subjective, concrete, literary, or formal words.
Syntactic Style Categorization:

Focuses on sentence syntax variations like simple, compound, complex, complex-compound, and others.
Draws inspiration from Feng, Banerjee, and Choi (2012) to categorize syntactic styles.
Quantifies stylistic elements by calculating the fraction of sentences falling into these categories.
This methodology outlines a comprehensive approach to evaluating content preservation and stylistic alignment, incorporating sophisticated techniques to analyze and quantify stylistic elements at various linguistic levels for more nuanced assessments.

Opinosis
The Opinosis section discusses how to quantify stylistic elements such as commas, semicolons, colons per sentence, sentences in a paragraph, and number of words in a sentence into a 5-dimensional vector. Here are the key points included:

The 5-dimensional vector represents a probability distribution over 5 categories, offering insights into the stylistic expression at different levels.
Stylistic alignment between generated and target text is computed by analyzing surface-level elements, syntactic style vectors, and lexical features.
The approach consists of:

Quantifying surface-level elements into a 5-dimensional vector to capture stylistic expressions.
Computing statistics on an author-specific corpus to understand the author's writing style.
Measuring stylistic alignment using mean squared error for lexical and surface-level alignment, and Jensen-Shannon divergence for syntactic style vectors.
Results and Analysis
The authors present a blend of qualitative and quantitative evaluations of their StyleLM model's performance in adapting to different authors' writing styles:

Qualitative Evaluation Table showcases text samples stylized for various authors using StyleLM. Noteworthy adaptations include changing words like 'catered' to 'kind', 'obliged', or 'ready to accept', and 'super' to 'extra' while maintaining semantic meaning. For Charles Dickens, transformations from 'AI is programmed' to 'brain is to learn' and 'rewarding' to 'gratification' illustrate author-specific adjustments over time.

The generated samples demonstrate the effectiveness of the approach by reflecting the target author's style and preserving content significantly.

Quantitative Evaluation employs an evaluation framework to test the StyleLM model on both content preservation and stylistic alignment metrics. The evaluation involves rewriting test corpora to match the style of different authors using fine-tuned StyleLM models. Test sets cover various domains like user reviews, Mark Twain's books, and an AI Wikipedia page.

Stylistic Alignment Comparison: Results suggest that author fine-tuned GPT-2 performs comparably to denoising LM with input text and outperforms other baselines. It even competes with entirely supervised methods, highlighting the effectiveness of the proposed StyleLM model.

Future Directions: The authors propose delving deeper into linguistic style understanding to enhance the generation process further. By incentivizing or penalizing alignment with different style attributes, they aim to refine the text generation process.