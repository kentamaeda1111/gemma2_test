5. Automated Data Curation for Robust Language Model Fine-Tuning
Jiuhai Chen, Jonas Mueller

This paper introduces CLEAR, an automated data curation pipeline designed to improve the robustness of language model fine-tuning. The core idea is to systematically improve the quality of instruction-tuning datasets by identifying and either correcting or removing low-quality data points. This is done without requiring a more powerful language model than the one being fine-tuned, unlike many existing approaches.

Here's a breakdown of the key aspects:

The Problem: Large language models (LLMs) are often fine-tuned on instruction-tuning datasets containing (prompt, target response) pairs. However, real-world datasets are often noisy, containing inaccurate, poorly written, irrelevant, or otherwise flawed examples. This noisy data can lead to poorly performing fine-tuned LLMs.

The CLEAR Pipeline: CLEAR addresses this by employing a two-stage process:

Auto-Filter: This stage automatically removes low-quality data points from the dataset. It uses a confidence-based approach (BSDetector) that leverages the LLM itself to estimate the quality of each response. Only data points with low confidence scores are removed, ensuring that only clearly bad examples are filtered out. This step requires no additional fine-tuning.

Auto-Correct: For datasets where fine-tuning is possible multiple times, this stage attempts to correct low-quality data points rather than simply removing them. The already fine-tuned LLM (from the Auto-Filter stage) generates a new response for the problematic prompt. A secondary confidence estimation process determines if the new response is confidently better than the original. Only then is the original response replaced. After this correction, the LLM can be fine-tuned again on the improved dataset.

Key Advantages:

Data-centric: CLEAR focuses on improving the data, rather than solely focusing on algorithmic improvements.

Model-agnostic: It can be used with any LLM and any fine-tuning procedure.

No need for a stronger LLM: The data curation process relies only on the LLM being fine-tuned, making it applicable even when access to more powerful models is limited.

Automated: The entire process is automated, reducing the need for manual data curation, which is time-consuming and prone to errors.

Conservative modifications: CLEAR uses confidence scores to ensure only confident changes are made to the dataset, preventing the introduction of biases or further errors.

Experiments: The authors evaluated CLEAR on three instruction-tuning datasets (SQuAD-N, Emails-N, DROP-N), testing its effectiveness across different LLMs (Llama-2 and GPT-3.5). The results consistently demonstrated that CLEAR improved the performance of fine-tuned models compared to using the original noisy data, even surpassing some zero-shot and few-shot baselines from stronger LLMs.

Limitations: The authors acknowledge that the current framework does not explicitly account for potential biases present in the original dataset.

In essence, CLEAR offers a novel and effective approach to data curation for LLM fine-tuning, enabling the training of more robust and accurate models. Its data-centric approach and model-agnostic nature make it a valuable tool for a wide range of LLM fine-tuning tasks.

