
1. XDAI: A Tuning-free Framework for Exploiting Pre-trained Language Models in Knowledge Grounded Dialogue Generation
Jifan Yu, Xiaohan Zhang, Yifan Xu, Xuanyu Lei, Xinyu Guan, Jing Zhang, Hou Lei, Juanzi Li, Jie Tang


This paper introduces XDAI, a tuning-free framework for building knowledge-grounded dialogue systems using large pre-trained language models (PLMs). The key idea is to effectively leverage the capabilities of PLMs without the expensive cost and complexity of fine-tuning, addressing a major bottleneck in deploying such systems.

Here's a breakdown of the key aspects:

1. The Problem:

Developing knowledge-grounded dialogue systems using PLMs is challenging due to:

High-quality Data Curation Obstacles: Collecting and preparing knowledge resources (knowledge bases, text, tables) and crafting domain-specific dialogue corpora for training is expensive and time-consuming.

Effectiveness vs. Efficiency Trade-off: Fine-tuning or constraining PLMs can improve performance but requires significant resources, potentially slowing down inference.

2. The XDAI Framework:

XDAI tackles these challenges with a two-part framework:

Offline Knowledge Curation System: This system prepares the knowledge resources needed for dialogue generation. It includes:

Data Collection: Gathering knowledge from various sources (knowledge bases like XLORE2, search engines). For domain-specific systems, seed concepts are used to guide collection.

Resource Integration: Transforming the collected heterogeneous knowledge into two unified formats: description-formatted (background knowledge) and QA-formatted (knowledge injection for specific dialogue turns).

Concept Expansion (optional): For domain-specific systems, this component expands the initial seed concepts by extracting and clustering noun phrases from the collected resources.

Online Dialogue Generation System: This system generates dialogue responses using the prepared knowledge and the current dialogue context. Key aspects are:

Prompt Manufacturing: A novel prompt construction method combines:

Dialogue history (most recent turns).

Dialogue knowledge (relevant QA pairs injected before relevant turns).

Background knowledge (description-formatted knowledge about the topic).

PLM Exploitation: A tuning-free approach employing a pre-trained PLM (e.g., GLM) to generate responses directly from the constructed prompt. No fine-tuning of the PLM is required.

3. Experiments and Evaluation:

The authors conducted extensive experiments, including:

Human Evaluation: Evaluating the quality of dialogues generated by XDAI compared to several baselines (general PLMs like GLM, Transformer-XL, CPM; dialogue-specific PLMs like PLATO-XL, EVA; controllable generation methods like FSB, Inverse Prompt) on both open-domain and domain-specific (Travel, Sports) dialogues using metrics like coherence, informativeness, engagingness, hallucination, inconsistency.

Turing Test: Comparing XDAI's responses to human responses to assess the naturalness of the generated dialogue.

Online Evaluation: Deploying XDAI in a real-world online environment to collect user feedback on user engagement and retention.

4. Results:

Human Evaluation: XDAI achieves competitive performance compared to baselines in open-domain and domain-specific dialogues, particularly excelling in informativeness and engagingness without any fine-tuning.

Turing Test: XDAI demonstrates comparable naturalness to other methods.

Online Evaluation: XDAI shows high user engagement and retention in the online setting.

5. Ablation Study:

Removing either the QA-formatted or description-formatted knowledge from XDAI's prompts negatively impacts performance, highlighting the importance of both types of knowledge.

6. Key Contributions:

A novel tuning-free framework for exploiting PLMs in knowledge-grounded dialogue generation.

A novel prompt manufacturing mechanism that effectively integrates knowledge into the dialogue generation process without fine-tuning.

Extensive experiments demonstrating XDAI's competitive performance and ease of use.

Interesting insights regarding the effectiveness of discrete prompts for knowledge-grounded dialogue and the advantages of general-purpose PLMs for such tasks.

In summary, XDAI offers a practical and efficient solution for building knowledge-grounded dialogue systems, overcoming significant hurdles in deploying PLMs for this challenging task. The framework's flexibility and ease of customization make it particularly valuable for researchers and developers with limited resources.