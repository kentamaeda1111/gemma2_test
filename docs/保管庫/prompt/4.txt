次は## 4. System Prompts in Fine-tuningに進みましょう。繰り返しになりますが、gemma 2の2bモデルという規模間のモデルで且つソクラテス風の口調のチャットボット、を目指していた、というのがありまして、ソクラテス的な問答という問い力、のような深いレイヤーのものではなく、口調というわりとレイヤーの浅いものを目指していた、という大前提があるのですが、gemma2はそもそもsystem promptという概念がないです。
@gemma2 の資料も見てもらえたらと思うのですが、基本的にはuserとmodelというroleしかない、というシンプルな設計思想です。そのため、学習データもsystem roleみたいなものが作れないです。且つuserから必ず対話を始めないといけない、という縛りがありました。その制約があるなかで、色々ためしたら、userの発言の前に必ず特定のキーワードを挿入したパターンがmodelのトレイン分析をしていて、いい結果になっていることが判明しました。例えばuserの発言の前に”あなたはソクラテスです”みたいなキーワードを必ず挿入する形です。特に"あなたは古代ギリシャの哲学者ソクラテスです。"で良い数値の結果が出ていました。これはsystem promptというわけではないのですが、gemma2が学習をするうえで、何か効用があったんだと思います。そこで以下の論文をチェックしてほしいのですが、私が体験したようなことを記述している論文はありますか？私がざっと見た感じ、system promptは学習時には必要ない、みたいなデータがほとんどで、私が体験したようなuserの発話の前に”あなたはソクラテスです”みたいな文言をいれることが学習の観点から有効みたいな情報が見当たらなかったのですが、もしそのような何用があれば具体的な論文及び箇所を抽出して教えて下さい。